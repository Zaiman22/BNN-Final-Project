{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf318e8-78e4-42c4-8e44-606ca5b81d80",
   "metadata": {},
   "source": [
    "# Brevitas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bec7a6-94b9-41a8-b445-7d977f71a661",
   "metadata": {},
   "source": [
    "## 1 Traditional Binary Neural Network (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86007cc-a84d-450b-b126-85b56ce5954e",
   "metadata": {},
   "source": [
    "### 1.1 Importing and checking hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "724a188a-fb28-4848-87d4-afc85901e7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.8.0+cu128\n",
      "Cuda is available: True\n",
      "device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "\n",
    "# for training model\n",
    "# import brevitas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch.optim as optim\n",
    "\n",
    "# fracbnn modules\n",
    "sys.path.append('./src')\n",
    "import utils as util\n",
    "import quantization as q\n",
    "importlib.reload(q)\n",
    "\n",
    "\n",
    "# # for dataset\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Checking version\n",
    "print(f'Torch version: {torch.__version__}')\n",
    "# i dont get how to use brevitas, many other paper such as fracbnn and reacnet also did not use brevitas actually\n",
    "# print(f'Brevitas version: {brevitas.__version__}')\n",
    "\n",
    "\n",
    "# checking hardware\n",
    "# if torch.cuda.is_available():\n",
    "print(f'Cuda is available: {torch.cuda.is_available()}')  # should be True\n",
    "print(f'device: {torch.cuda.get_device_name(0)}')  # should say RTX 3060\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c61fa43",
   "metadata": {},
   "source": [
    "## 1.2 Importing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ea74f",
   "metadata": {},
   "source": [
    "MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb781b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/home/jovyan/dataset'\n",
    "\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=dataset_dir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=dataset_dir,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef80d3a",
   "metadata": {},
   "source": [
    "Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed54e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [01:03<00:00, 2.69MB/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/home/jovyan/dataset'\n",
    "\n",
    "\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=dataset_dir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=dataset_dir,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3dc39c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(training_data, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87fc33c",
   "metadata": {},
   "source": [
    "## 1.3 Binary Genetic algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53e0cf5",
   "metadata": {},
   "source": [
    "### 1.3.0 Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c11b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GA Helpers ---\n",
    "def generate_weight(x, y):\n",
    "    return 2 * torch.randint(0, 2, (x, y)) - 1  # -1 or 1\n",
    "\n",
    "def mutate_weight(weight, mutation_rate=0.2):\n",
    "    x, y = weight.shape\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            if random.random() < mutation_rate:\n",
    "                weight[i, j] *= -1\n",
    "    return weight\n",
    "\n",
    "def get_fitness(target, candidate):\n",
    "    # Fitness = number of matching elements\n",
    "    return torch.sum(target == candidate).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836121bd",
   "metadata": {},
   "source": [
    "### 1.3.1 Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0900164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: Best fitness = 8\n",
      "Generation 1: Best fitness = 8\n",
      "Generation 2: Best fitness = 8\n",
      "Generation 3: Best fitness = 9\n",
      "ðŸŽ¯ Found perfect match!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, -1,  1],\n",
      "        [-1,  1, -1],\n",
      "        [ 1, -1,  1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "initial_population = 50\n",
    "generations = 100\n",
    "mutation_rate = 0.1\n",
    "survivor =25\n",
    "\n",
    "\n",
    "\n",
    "# --- Target ---\n",
    "target_weight = torch.tensor([[1, -1, 1],\n",
    "                              [-1, 1, -1],\n",
    "                              [1, -1, 1]])\n",
    "\n",
    "# --- Step 1: Initialize population ---\n",
    "population = [generate_weight(3, 3) for _ in range(initial_population)]\n",
    "\n",
    "# --- GA Loop ---\n",
    "for gen in range(generations):\n",
    "    # Step 2: Evaluate fitness\n",
    "    fitness_scores = [get_fitness(target_weight, ind) for ind in population]\n",
    "    \n",
    "    # Step 3: Select best (elitism: keep top 2)\n",
    "    sorted_pop = [p for _, p in sorted(zip(fitness_scores, population), key=lambda x: x[0], reverse=True)]\n",
    "    best = sorted_pop[0]\n",
    "    best_fitness = max(fitness_scores)\n",
    "    \n",
    "    print(f\"Generation {gen}: Best fitness = {best_fitness}\")\n",
    "    \n",
    "    # Stop early if perfect solution found\n",
    "    if best_fitness == target_weight.numel():\n",
    "        print(\"ðŸŽ¯ Found perfect match!\")\n",
    "        break\n",
    "    \n",
    "    # Step 4: Create next generation (mutations of top parents)\n",
    "    new_population = []\n",
    "    for i in range(initial_population):\n",
    "        parent = random.choice(sorted_pop[:survivor]).clone()  # pick from top 5\n",
    "        child = mutate_weight(parent.clone(), mutation_rate)\n",
    "        new_population.append(child)\n",
    "    \n",
    "    population = new_population\n",
    "\n",
    "# --- Show best solution ---\n",
    "plt.imshow(best.numpy(), cmap=\"gray\", interpolation=\"nearest\")\n",
    "plt.colorbar(label=\"Weight Value\")\n",
    "plt.title(f\"Best Evolved Matrix (Fitness={best_fitness})\")\n",
    "plt.show()\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4edc8e",
   "metadata": {},
   "source": [
    "### 1.3.2 Multi channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49672738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: Best fitness = 29\n",
      "Generation 1: Best fitness = 31\n",
      "Generation 2: Best fitness = 35\n",
      "Generation 3: Best fitness = 36\n",
      "Generation 4: Best fitness = 36\n",
      "Generation 5: Best fitness = 37\n",
      "Generation 6: Best fitness = 39\n",
      "Generation 7: Best fitness = 40\n",
      "Generation 8: Best fitness = 40\n",
      "Generation 9: Best fitness = 40\n",
      "Generation 10: Best fitness = 40\n",
      "Generation 11: Best fitness = 41\n",
      "Generation 12: Best fitness = 41\n",
      "Generation 13: Best fitness = 41\n",
      "Generation 14: Best fitness = 41\n",
      "Generation 15: Best fitness = 41\n",
      "Generation 16: Best fitness = 41\n",
      "Generation 17: Best fitness = 41\n",
      "Generation 18: Best fitness = 42\n",
      "Generation 19: Best fitness = 42\n",
      "Generation 20: Best fitness = 42\n",
      "Generation 21: Best fitness = 42\n",
      "Generation 22: Best fitness = 42\n",
      "Generation 23: Best fitness = 42\n",
      "Generation 24: Best fitness = 42\n",
      "Generation 25: Best fitness = 43\n",
      "Generation 26: Best fitness = 43\n",
      "Generation 27: Best fitness = 43\n",
      "Generation 28: Best fitness = 43\n",
      "Generation 29: Best fitness = 43\n",
      "Generation 30: Best fitness = 43\n",
      "Generation 31: Best fitness = 43\n",
      "Generation 32: Best fitness = 43\n",
      "Generation 33: Best fitness = 43\n",
      "Generation 34: Best fitness = 43\n",
      "Generation 35: Best fitness = 43\n",
      "Generation 36: Best fitness = 43\n",
      "Generation 37: Best fitness = 43\n",
      "Generation 38: Best fitness = 45\n",
      "ðŸŽ¯ Found perfect match!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x1500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Multi channel target (5 channel)\n",
    "target_weight = torch.tensor([[[1, -1, 1],\n",
    "                              [-1, 1, -1],\n",
    "                              [1, -1, 1]],\n",
    "\n",
    "                              [[1, -1, 1],\n",
    "                              [1, -1, 1],\n",
    "                              [1, -1, 1]],\n",
    "\n",
    "                              [[1, 1, 1],\n",
    "                              [-1, -1, -1],\n",
    "                              [1, 1, 1]],\n",
    "\n",
    "                              [[-1, 1, 1],\n",
    "                              [1, -1, 1],\n",
    "                              [1, 1, -1]],\n",
    "\n",
    "                              [[1, 1, -1],\n",
    "                              [1, -1, 1],\n",
    "                              [-1, 1, 1]]\n",
    "                            \n",
    "                              ])\n",
    "\n",
    "num_channel = target_weight.shape[0]\n",
    "population  = 50\n",
    "generations = 1000\n",
    "\n",
    "weight = [torch.stack([generate_weight(3, 3) for _ in range(num_channel)]) for _ in range(population)]\n",
    "\n",
    "\n",
    "# --- GA Loop ---\n",
    "for gen in range(generations):\n",
    "    # Step 2: Evaluate fitness\n",
    "    # population loop\n",
    "    fitness_scores = []\n",
    "    for ind in weight:  # each individual is a tensor of shape [num_channel, 3, 3]\n",
    "        fitness = 0\n",
    "        for chann in range(num_channel):\n",
    "            fitness += get_fitness(target_weight[chann], ind[chann])\n",
    "        fitness_scores.append(fitness)\n",
    "\n",
    "    # Step 3: Select best (elitism: keep top 2)\n",
    "    sorted_pop = [p for _, p in sorted(zip(fitness_scores, weight), key=lambda x: x[0], reverse=True)]\n",
    "    best = sorted_pop[0]\n",
    "    best_fitness = max(fitness_scores)\n",
    "    \n",
    "    print(f\"Generation {gen}: Best fitness = {best_fitness}\")\n",
    "    \n",
    "    # Stop early if perfect solution found\n",
    "    if best_fitness == target_weight.numel():\n",
    "        print(\"ðŸŽ¯ Found perfect match!\")\n",
    "        break\n",
    "    \n",
    "    # Step 4: Create next generation (mutations of top parents)\n",
    "    # Step 4: Create next generation (mutations of top parents)\n",
    "    weight = []\n",
    "\n",
    "    for _ in range(population):\n",
    "        parent = random.choice(sorted_pop[:5]).clone()  # pick a top parent\n",
    "        child = torch.stack([mutate_weight(parent[ch], mutation_rate) for ch in range(num_channel)])\n",
    "        new_population.append(child)\n",
    "\n",
    "    weight = new_population\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(num_channel, 2, figsize=(6, 3 * num_channel))\n",
    "\n",
    "for ch in range(num_channel):\n",
    "    # Target\n",
    "    axes[ch, 0].imshow(target_weight[ch].numpy(), cmap=\"gray\", interpolation=\"nearest\")\n",
    "    axes[ch, 0].set_title(f\"Target (ch={ch})\")\n",
    "    axes[ch, 0].axis(\"off\")\n",
    "\n",
    "    # Best\n",
    "    axes[ch, 1].imshow(best[ch].numpy(), cmap=\"gray\", interpolation=\"nearest\")\n",
    "    axes[ch, 1].set_title(f\"Best (ch={ch})\")\n",
    "    axes[ch, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d85bd7",
   "metadata": {},
   "source": [
    "## 1.4 Creating VGG-16 binary code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25bfa7c",
   "metadata": {},
   "source": [
    "### 1.4.1 Initial VGG using binary weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c5ff4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class binary_VGG_small(nn.Module):\n",
    "    def __init__(self, num_classes=10, batch_size=128):\n",
    "        super(binary_VGG_small, self).__init__()\n",
    "\n",
    "        ''' The input layer is binarized! '''\n",
    "        self.conv1 =  q.BinaryConv2d(8, 26, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv2 = q.BinaryConv2d(26, 24, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv3 = q.BinaryConv2d(24, 31, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.binarize = q.QuantSign.apply\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = q.BinaryLinear(31*7*7, num_classes, bias=False)\n",
    "        num_gpus = 1\n",
    "        assert batch_size % num_gpus == 0, \\\n",
    "            \"Given batch size cannot evenly distributed to available gpus.\"\n",
    "        N = batch_size // num_gpus\n",
    "\n",
    "        self.encoder = q.InputEncoder(input_size=(1,1,28,28), resolution=32) # 255/32=8 -> from 1 channel becomes 8 channel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.binarize(self.conv1(x))\n",
    "        x = self.binarize(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.binarize(x)\n",
    "        x = self.binarize(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.binarize(x)\n",
    "        x = self.flatten(x)\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def forward_until(self, x, stop='conv2'):\n",
    "        x = self.encoder(x)\n",
    "        x = self.binarize(self.conv1(x))\n",
    "        if stop == 'conv1': return x\n",
    "        x = self.binarize(self.conv2(x))\n",
    "        if stop == 'conv2': return x\n",
    "        x = self.pool(x)\n",
    "        if stop == 'pool1': return x\n",
    "        x = self.binarize(self.conv3(x))\n",
    "        if stop == 'conv3': return x\n",
    "        x = self.pool(x)\n",
    "        x = self.binarize(x)\n",
    "        if stop == 'pool2': return x\n",
    "        x = self.flatten(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c949856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tensor([[ 54.6774, -11.3226, -25.3871, -18.0968, -54.5484,   6.8065, -39.7097,\n",
      "          14.4194, -39.5806,  28.6774]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = binary_VGG_small(num_classes=10).to(device)\n",
    "# put input on the same device\n",
    "input = torch.randn(1, 1, 28, 28).to(device)\n",
    "output = model(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "eb588b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current learning rate = 1.0\n",
      "Epoch: [1][ 99/469]\tLoss  87.90\tAcc  29.23\tTime/batch 0.01\n",
      "Epoch: [1][199/469]\tLoss  62.51\tAcc  39.14\tTime/batch 0.01\n",
      "Epoch: [1][299/469]\tLoss  53.55\tAcc  44.24\tTime/batch 0.01\n",
      "Epoch: [1][399/469]\tLoss  48.59\tAcc  46.13\tTime/batch 0.01\n",
      "epoch 1\n",
      "Accuracy of the network on the 10000 test images: 61.7 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 61.7\n",
      "current learning rate = 1.0\n",
      "Epoch: [2][ 99/469]\tLoss  30.04\tAcc  55.60\tTime/batch 0.01\n",
      "Epoch: [2][199/469]\tLoss  31.04\tAcc  53.06\tTime/batch 0.01\n",
      "Epoch: [2][299/469]\tLoss  29.58\tAcc  53.49\tTime/batch 0.01\n",
      "Epoch: [2][399/469]\tLoss  30.74\tAcc  52.89\tTime/batch 0.01\n",
      "epoch 2\n",
      "Accuracy of the network on the 10000 test images: 32.9 %\n",
      "The best test accuracy so far: 61.7\n",
      "current learning rate = 1.0\n",
      "Epoch: [3][ 99/469]\tLoss  34.11\tAcc  51.88\tTime/batch 0.01\n",
      "Epoch: [3][199/469]\tLoss  31.93\tAcc  53.14\tTime/batch 0.01\n",
      "Epoch: [3][299/469]\tLoss  31.75\tAcc  52.70\tTime/batch 0.01\n",
      "Epoch: [3][399/469]\tLoss  31.79\tAcc  53.12\tTime/batch 0.01\n",
      "epoch 3\n",
      "Accuracy of the network on the 10000 test images: 62.9 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 62.9\n",
      "current learning rate = 1.0\n",
      "Epoch: [4][ 99/469]\tLoss  30.56\tAcc  55.70\tTime/batch 0.01\n",
      "Epoch: [4][199/469]\tLoss  32.87\tAcc  55.01\tTime/batch 0.01\n",
      "Epoch: [4][299/469]\tLoss  30.22\tAcc  56.93\tTime/batch 0.01\n",
      "Epoch: [4][399/469]\tLoss  31.33\tAcc  56.80\tTime/batch 0.01\n",
      "epoch 4\n",
      "Accuracy of the network on the 10000 test images: 27.2 %\n",
      "The best test accuracy so far: 62.9\n",
      "current learning rate = 1.0\n",
      "Epoch: [5][ 99/469]\tLoss  34.15\tAcc  54.98\tTime/batch 0.01\n",
      "Epoch: [5][199/469]\tLoss  31.23\tAcc  55.29\tTime/batch 0.01\n",
      "Epoch: [5][299/469]\tLoss  31.04\tAcc  54.72\tTime/batch 0.01\n",
      "Epoch: [5][399/469]\tLoss  30.95\tAcc  54.55\tTime/batch 0.01\n",
      "epoch 5\n",
      "Accuracy of the network on the 10000 test images: 60.8 %\n",
      "The best test accuracy so far: 62.9\n",
      "current learning rate = 0.1\n",
      "Epoch: [6][ 99/469]\tLoss   6.80\tAcc  79.64\tTime/batch 0.01\n",
      "Epoch: [6][199/469]\tLoss   5.55\tAcc  81.35\tTime/batch 0.01\n",
      "Epoch: [6][299/469]\tLoss   4.85\tAcc  82.49\tTime/batch 0.01\n",
      "Epoch: [6][399/469]\tLoss   4.68\tAcc  82.69\tTime/batch 0.01\n",
      "epoch 6\n",
      "Accuracy of the network on the 10000 test images: 76.7 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 76.7\n",
      "current learning rate = 0.1\n",
      "Epoch: [7][ 99/469]\tLoss   5.94\tAcc  79.70\tTime/batch 0.01\n",
      "Epoch: [7][199/469]\tLoss   6.28\tAcc  80.22\tTime/batch 0.01\n",
      "Epoch: [7][299/469]\tLoss   6.97\tAcc  79.92\tTime/batch 0.01\n",
      "Epoch: [7][399/469]\tLoss   9.46\tAcc  78.05\tTime/batch 0.01\n",
      "epoch 7\n",
      "Accuracy of the network on the 10000 test images: 80.9 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 80.9\n",
      "current learning rate = 0.1\n",
      "Epoch: [8][ 99/469]\tLoss  11.81\tAcc  76.03\tTime/batch 0.01\n",
      "Epoch: [8][199/469]\tLoss  11.43\tAcc  76.18\tTime/batch 0.01\n",
      "Epoch: [8][299/469]\tLoss  17.26\tAcc  73.11\tTime/batch 0.01\n",
      "Epoch: [8][399/469]\tLoss  15.05\tAcc  74.68\tTime/batch 0.01\n",
      "epoch 8\n",
      "Accuracy of the network on the 10000 test images: 80.5 %\n",
      "The best test accuracy so far: 80.9\n",
      "current learning rate = 0.1\n",
      "Epoch: [9][ 99/469]\tLoss  17.13\tAcc  71.78\tTime/batch 0.01\n",
      "Epoch: [9][199/469]\tLoss  13.49\tAcc  74.61\tTime/batch 0.01\n",
      "Epoch: [9][299/469]\tLoss  13.30\tAcc  75.38\tTime/batch 0.01\n",
      "Epoch: [9][399/469]\tLoss  13.30\tAcc  75.07\tTime/batch 0.01\n",
      "epoch 9\n",
      "Accuracy of the network on the 10000 test images: 79.4 %\n",
      "The best test accuracy so far: 80.9\n",
      "current learning rate = 0.1\n",
      "Epoch: [10][ 99/469]\tLoss  16.75\tAcc  71.30\tTime/batch 0.01\n",
      "Epoch: [10][199/469]\tLoss  15.54\tAcc  72.04\tTime/batch 0.01\n",
      "Epoch: [10][299/469]\tLoss  19.00\tAcc  70.99\tTime/batch 0.01\n",
      "Epoch: [10][399/469]\tLoss  15.93\tAcc  73.28\tTime/batch 0.01\n",
      "epoch 10\n",
      "Accuracy of the network on the 10000 test images: 75.9 %\n",
      "The best test accuracy so far: 80.9\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [11][ 99/469]\tLoss   5.00\tAcc  87.52\tTime/batch 0.01\n",
      "Epoch: [11][199/469]\tLoss   4.20\tAcc  88.82\tTime/batch 0.01\n",
      "Epoch: [11][299/469]\tLoss   3.70\tAcc  89.59\tTime/batch 0.01\n",
      "Epoch: [11][399/469]\tLoss   3.41\tAcc  89.99\tTime/batch 0.01\n",
      "epoch 11\n",
      "Accuracy of the network on the 10000 test images: 91.9 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 91.9\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [12][ 99/469]\tLoss   2.34\tAcc  91.31\tTime/batch 0.01\n",
      "Epoch: [12][199/469]\tLoss   2.27\tAcc  91.48\tTime/batch 0.01\n",
      "Epoch: [12][299/469]\tLoss   2.17\tAcc  91.72\tTime/batch 0.01\n",
      "Epoch: [12][399/469]\tLoss   2.14\tAcc  91.75\tTime/batch 0.01\n",
      "epoch 12\n",
      "Accuracy of the network on the 10000 test images: 93.5 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 93.5\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [13][ 99/469]\tLoss   1.85\tAcc  92.01\tTime/batch 0.01\n",
      "Epoch: [13][199/469]\tLoss   1.82\tAcc  91.83\tTime/batch 0.01\n",
      "Epoch: [13][299/469]\tLoss   1.72\tAcc  92.10\tTime/batch 0.01\n",
      "Epoch: [13][399/469]\tLoss   1.69\tAcc  92.15\tTime/batch 0.01\n",
      "epoch 13\n",
      "Accuracy of the network on the 10000 test images: 92.2 %\n",
      "The best test accuracy so far: 93.5\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [14][ 99/469]\tLoss   1.39\tAcc  92.93\tTime/batch 0.01\n",
      "Epoch: [14][199/469]\tLoss   1.52\tAcc  92.52\tTime/batch 0.01\n",
      "Epoch: [14][299/469]\tLoss   1.52\tAcc  92.47\tTime/batch 0.01\n",
      "Epoch: [14][399/469]\tLoss   1.51\tAcc  92.54\tTime/batch 0.01\n",
      "epoch 14\n",
      "Accuracy of the network on the 10000 test images: 93.2 %\n",
      "The best test accuracy so far: 93.5\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [15][ 99/469]\tLoss   1.70\tAcc  92.03\tTime/batch 0.01\n",
      "Epoch: [15][199/469]\tLoss   1.71\tAcc  91.86\tTime/batch 0.01\n",
      "Epoch: [15][299/469]\tLoss   1.61\tAcc  92.37\tTime/batch 0.01\n",
      "Epoch: [15][399/469]\tLoss   1.67\tAcc  92.19\tTime/batch 0.01\n",
      "epoch 15\n",
      "Accuracy of the network on the 10000 test images: 86.2 %\n",
      "The best test accuracy so far: 93.5\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [16][ 99/469]\tLoss   2.34\tAcc  90.78\tTime/batch 0.01\n",
      "Epoch: [16][199/469]\tLoss   1.95\tAcc  92.10\tTime/batch 0.01\n",
      "Epoch: [16][299/469]\tLoss   2.01\tAcc  91.93\tTime/batch 0.01\n",
      "Epoch: [16][399/469]\tLoss   2.07\tAcc  91.78\tTime/batch 0.01\n",
      "epoch 16\n",
      "Accuracy of the network on the 10000 test images: 90.5 %\n",
      "The best test accuracy so far: 93.5\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [17][ 99/469]\tLoss   1.77\tAcc  93.10\tTime/batch 0.01\n",
      "Epoch: [17][199/469]\tLoss   1.82\tAcc  92.88\tTime/batch 0.01\n",
      "Epoch: [17][299/469]\tLoss   2.04\tAcc  92.27\tTime/batch 0.01\n",
      "Epoch: [17][399/469]\tLoss   2.02\tAcc  92.38\tTime/batch 0.01\n",
      "epoch 17\n",
      "Accuracy of the network on the 10000 test images: 93.0 %\n",
      "The best test accuracy so far: 93.5\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [18][ 99/469]\tLoss   2.83\tAcc  90.05\tTime/batch 0.01\n",
      "Epoch: [18][199/469]\tLoss   3.20\tAcc  89.40\tTime/batch 0.01\n",
      "Epoch: [18][299/469]\tLoss   3.04\tAcc  89.72\tTime/batch 0.01\n",
      "Epoch: [18][399/469]\tLoss   3.14\tAcc  89.51\tTime/batch 0.01\n",
      "epoch 18\n",
      "Accuracy of the network on the 10000 test images: 92.1 %\n",
      "The best test accuracy so far: 93.5\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [19][ 99/469]\tLoss   2.66\tAcc  90.99\tTime/batch 0.01\n",
      "Epoch: [19][199/469]\tLoss   3.00\tAcc  90.55\tTime/batch 0.01\n",
      "Epoch: [19][299/469]\tLoss   3.29\tAcc  89.91\tTime/batch 0.01\n",
      "Epoch: [19][399/469]\tLoss   3.70\tAcc  89.10\tTime/batch 0.01\n",
      "epoch 19\n",
      "Accuracy of the network on the 10000 test images: 86.6 %\n",
      "The best test accuracy so far: 93.5\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [20][ 99/469]\tLoss   3.27\tAcc  90.22\tTime/batch 0.01\n",
      "Epoch: [20][199/469]\tLoss   3.66\tAcc  89.73\tTime/batch 0.01\n",
      "Epoch: [20][299/469]\tLoss   4.18\tAcc  88.68\tTime/batch 0.01\n",
      "Epoch: [20][399/469]\tLoss   4.64\tAcc  87.80\tTime/batch 0.01\n",
      "epoch 20\n",
      "Accuracy of the network on the 10000 test images: 94.3 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 94.3\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [21][ 99/469]\tLoss   1.16\tAcc  95.70\tTime/batch 0.01\n",
      "Epoch: [21][199/469]\tLoss   1.18\tAcc  95.70\tTime/batch 0.01\n",
      "Epoch: [21][299/469]\tLoss   1.20\tAcc  95.56\tTime/batch 0.01\n",
      "Epoch: [21][399/469]\tLoss   1.19\tAcc  95.48\tTime/batch 0.01\n",
      "epoch 21\n",
      "Accuracy of the network on the 10000 test images: 96.2 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 96.2\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [22][ 99/469]\tLoss   1.03\tAcc  95.54\tTime/batch 0.01\n",
      "Epoch: [22][199/469]\tLoss   1.05\tAcc  95.52\tTime/batch 0.01\n",
      "Epoch: [22][299/469]\tLoss   1.04\tAcc  95.55\tTime/batch 0.01\n",
      "Epoch: [22][399/469]\tLoss   1.04\tAcc  95.57\tTime/batch 0.01\n",
      "epoch 22\n",
      "Accuracy of the network on the 10000 test images: 96.0 %\n",
      "The best test accuracy so far: 96.2\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [23][ 99/469]\tLoss   0.82\tAcc  96.13\tTime/batch 0.01\n",
      "Epoch: [23][199/469]\tLoss   0.84\tAcc  95.99\tTime/batch 0.01\n",
      "Epoch: [23][299/469]\tLoss   0.92\tAcc  95.75\tTime/batch 0.01\n",
      "Epoch: [23][399/469]\tLoss   0.94\tAcc  95.70\tTime/batch 0.01\n",
      "epoch 23\n",
      "Accuracy of the network on the 10000 test images: 95.8 %\n",
      "The best test accuracy so far: 96.2\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [24][ 99/469]\tLoss   0.87\tAcc  95.65\tTime/batch 0.01\n",
      "Epoch: [24][199/469]\tLoss   0.87\tAcc  95.70\tTime/batch 0.01\n",
      "Epoch: [24][299/469]\tLoss   0.86\tAcc  95.78\tTime/batch 0.01\n",
      "Epoch: [24][399/469]\tLoss   0.90\tAcc  95.56\tTime/batch 0.01\n",
      "epoch 24\n",
      "Accuracy of the network on the 10000 test images: 96.7 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 96.7\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [25][ 99/469]\tLoss   0.92\tAcc  95.76\tTime/batch 0.01\n",
      "Epoch: [25][199/469]\tLoss   0.91\tAcc  95.61\tTime/batch 0.01\n",
      "Epoch: [25][299/469]\tLoss   0.92\tAcc  95.52\tTime/batch 0.01\n",
      "Epoch: [25][399/469]\tLoss   0.90\tAcc  95.61\tTime/batch 0.01\n",
      "epoch 25\n",
      "Accuracy of the network on the 10000 test images: 96.0 %\n",
      "The best test accuracy so far: 96.7\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [26][ 99/469]\tLoss   0.85\tAcc  96.02\tTime/batch 0.01\n",
      "Epoch: [26][199/469]\tLoss   0.91\tAcc  95.64\tTime/batch 0.01\n",
      "Epoch: [26][299/469]\tLoss   0.94\tAcc  95.51\tTime/batch 0.01\n",
      "Epoch: [26][399/469]\tLoss   0.92\tAcc  95.53\tTime/batch 0.01\n",
      "epoch 26\n",
      "Accuracy of the network on the 10000 test images: 95.5 %\n",
      "The best test accuracy so far: 96.7\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [27][ 99/469]\tLoss   0.93\tAcc  95.11\tTime/batch 0.01\n",
      "Epoch: [27][199/469]\tLoss   0.95\tAcc  95.20\tTime/batch 0.01\n",
      "Epoch: [27][299/469]\tLoss   0.92\tAcc  95.38\tTime/batch 0.01\n",
      "Epoch: [27][399/469]\tLoss   0.91\tAcc  95.41\tTime/batch 0.01\n",
      "epoch 27\n",
      "Accuracy of the network on the 10000 test images: 95.9 %\n",
      "The best test accuracy so far: 96.7\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [28][ 99/469]\tLoss   0.87\tAcc  95.54\tTime/batch 0.01\n",
      "Epoch: [28][199/469]\tLoss   0.86\tAcc  95.54\tTime/batch 0.01\n",
      "Epoch: [28][299/469]\tLoss   0.86\tAcc  95.48\tTime/batch 0.01\n",
      "Epoch: [28][399/469]\tLoss   0.90\tAcc  95.43\tTime/batch 0.01\n",
      "epoch 28\n",
      "Accuracy of the network on the 10000 test images: 96.3 %\n",
      "The best test accuracy so far: 96.7\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [29][ 99/469]\tLoss   0.82\tAcc  95.83\tTime/batch 0.01\n",
      "Epoch: [29][199/469]\tLoss   0.85\tAcc  95.63\tTime/batch 0.01\n",
      "Epoch: [29][299/469]\tLoss   0.88\tAcc  95.45\tTime/batch 0.01\n",
      "Epoch: [29][399/469]\tLoss   0.90\tAcc  95.36\tTime/batch 0.01\n",
      "epoch 29\n",
      "Accuracy of the network on the 10000 test images: 94.3 %\n",
      "The best test accuracy so far: 96.7\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [30][ 99/469]\tLoss   0.79\tAcc  95.62\tTime/batch 0.01\n",
      "Epoch: [30][199/469]\tLoss   0.85\tAcc  95.34\tTime/batch 0.01\n",
      "Epoch: [30][299/469]\tLoss   0.96\tAcc  95.07\tTime/batch 0.01\n",
      "Epoch: [30][399/469]\tLoss   0.96\tAcc  95.13\tTime/batch 0.01\n",
      "epoch 30\n",
      "Accuracy of the network on the 10000 test images: 95.6 %\n",
      "The best test accuracy so far: 96.7\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [31][ 99/469]\tLoss   0.55\tAcc  96.84\tTime/batch 0.01\n",
      "Epoch: [31][199/469]\tLoss   0.56\tAcc  96.92\tTime/batch 0.01\n",
      "Epoch: [31][299/469]\tLoss   0.55\tAcc  96.94\tTime/batch 0.01\n",
      "Epoch: [31][399/469]\tLoss   0.54\tAcc  96.94\tTime/batch 0.01\n",
      "epoch 31\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 97.2\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [32][ 99/469]\tLoss   0.51\tAcc  96.99\tTime/batch 0.01\n",
      "Epoch: [32][199/469]\tLoss   0.52\tAcc  97.07\tTime/batch 0.01\n",
      "Epoch: [32][299/469]\tLoss   0.50\tAcc  97.10\tTime/batch 0.01\n",
      "Epoch: [32][399/469]\tLoss   0.51\tAcc  97.10\tTime/batch 0.01\n",
      "epoch 32\n",
      "Accuracy of the network on the 10000 test images: 97.0 %\n",
      "The best test accuracy so far: 97.2\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [33][ 99/469]\tLoss   0.48\tAcc  97.15\tTime/batch 0.01\n",
      "Epoch: [33][199/469]\tLoss   0.51\tAcc  97.06\tTime/batch 0.01\n",
      "Epoch: [33][299/469]\tLoss   0.54\tAcc  97.05\tTime/batch 0.01\n",
      "Epoch: [33][399/469]\tLoss   0.52\tAcc  97.07\tTime/batch 0.01\n",
      "epoch 33\n",
      "Accuracy of the network on the 10000 test images: 96.9 %\n",
      "The best test accuracy so far: 97.2\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [34][ 99/469]\tLoss   0.47\tAcc  97.25\tTime/batch 0.01\n",
      "Epoch: [34][199/469]\tLoss   0.49\tAcc  97.19\tTime/batch 0.01\n",
      "Epoch: [34][299/469]\tLoss   0.50\tAcc  97.15\tTime/batch 0.01\n",
      "Epoch: [34][399/469]\tLoss   0.49\tAcc  97.16\tTime/batch 0.01\n",
      "epoch 34\n",
      "Accuracy of the network on the 10000 test images: 96.9 %\n",
      "The best test accuracy so far: 97.2\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [35][ 99/469]\tLoss   0.49\tAcc  97.07\tTime/batch 0.01\n",
      "Epoch: [35][199/469]\tLoss   0.48\tAcc  97.13\tTime/batch 0.01\n",
      "Epoch: [35][299/469]\tLoss   0.49\tAcc  97.04\tTime/batch 0.01\n",
      "Epoch: [35][399/469]\tLoss   0.49\tAcc  96.98\tTime/batch 0.01\n",
      "epoch 35\n",
      "Accuracy of the network on the 10000 test images: 96.8 %\n",
      "The best test accuracy so far: 97.2\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [36][ 99/469]\tLoss   0.50\tAcc  97.12\tTime/batch 0.01\n",
      "Epoch: [36][199/469]\tLoss   0.48\tAcc  97.09\tTime/batch 0.01\n",
      "Epoch: [36][299/469]\tLoss   0.47\tAcc  97.10\tTime/batch 0.01\n",
      "Epoch: [36][399/469]\tLoss   0.47\tAcc  97.10\tTime/batch 0.01\n",
      "epoch 36\n",
      "Accuracy of the network on the 10000 test images: 96.6 %\n",
      "The best test accuracy so far: 97.2\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [37][ 99/469]\tLoss   0.48\tAcc  97.12\tTime/batch 0.01\n",
      "Epoch: [37][199/469]\tLoss   0.49\tAcc  97.07\tTime/batch 0.01\n",
      "Epoch: [37][299/469]\tLoss   0.48\tAcc  97.07\tTime/batch 0.01\n",
      "Epoch: [37][399/469]\tLoss   0.49\tAcc  97.03\tTime/batch 0.01\n",
      "epoch 37\n",
      "Accuracy of the network on the 10000 test images: 97.0 %\n",
      "The best test accuracy so far: 97.2\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [38][ 99/469]\tLoss   0.45\tAcc  97.09\tTime/batch 0.01\n",
      "Epoch: [38][199/469]\tLoss   0.46\tAcc  97.14\tTime/batch 0.01\n",
      "Epoch: [38][299/469]\tLoss   0.46\tAcc  97.08\tTime/batch 0.01\n",
      "Epoch: [38][399/469]\tLoss   0.50\tAcc  96.92\tTime/batch 0.01\n",
      "epoch 38\n",
      "Accuracy of the network on the 10000 test images: 97.1 %\n",
      "The best test accuracy so far: 97.2\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [39][ 99/469]\tLoss   0.48\tAcc  96.91\tTime/batch 0.01\n",
      "Epoch: [39][199/469]\tLoss   0.44\tAcc  97.01\tTime/batch 0.01\n",
      "Epoch: [39][299/469]\tLoss   0.46\tAcc  97.04\tTime/batch 0.01\n",
      "Epoch: [39][399/469]\tLoss   0.45\tAcc  97.10\tTime/batch 0.01\n",
      "epoch 39\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.2\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [40][ 99/469]\tLoss   0.46\tAcc  97.14\tTime/batch 0.01\n",
      "Epoch: [40][199/469]\tLoss   0.42\tAcc  97.23\tTime/batch 0.01\n",
      "Epoch: [40][299/469]\tLoss   0.44\tAcc  97.10\tTime/batch 0.01\n",
      "Epoch: [40][399/469]\tLoss   0.46\tAcc  97.01\tTime/batch 0.01\n",
      "epoch 40\n",
      "Accuracy of the network on the 10000 test images: 96.5 %\n",
      "The best test accuracy so far: 97.2\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [41][ 99/469]\tLoss   0.38\tAcc  97.38\tTime/batch 0.01\n",
      "Epoch: [41][199/469]\tLoss   0.39\tAcc  97.41\tTime/batch 0.01\n",
      "Epoch: [41][299/469]\tLoss   0.37\tAcc  97.46\tTime/batch 0.01\n",
      "Epoch: [41][399/469]\tLoss   0.36\tAcc  97.51\tTime/batch 0.01\n",
      "epoch 41\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 97.2\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [42][ 99/469]\tLoss   0.35\tAcc  97.54\tTime/batch 0.01\n",
      "Epoch: [42][199/469]\tLoss   0.35\tAcc  97.64\tTime/batch 0.01\n",
      "Epoch: [42][299/469]\tLoss   0.36\tAcc  97.55\tTime/batch 0.01\n",
      "Epoch: [42][399/469]\tLoss   0.35\tAcc  97.59\tTime/batch 0.01\n",
      "epoch 42\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [43][ 99/469]\tLoss   0.37\tAcc  97.45\tTime/batch 0.01\n",
      "Epoch: [43][199/469]\tLoss   0.35\tAcc  97.54\tTime/batch 0.01\n",
      "Epoch: [43][299/469]\tLoss   0.36\tAcc  97.49\tTime/batch 0.01\n",
      "Epoch: [43][399/469]\tLoss   0.37\tAcc  97.44\tTime/batch 0.01\n",
      "epoch 43\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [44][ 99/469]\tLoss   0.34\tAcc  97.61\tTime/batch 0.01\n",
      "Epoch: [44][199/469]\tLoss   0.35\tAcc  97.61\tTime/batch 0.01\n",
      "Epoch: [44][299/469]\tLoss   0.36\tAcc  97.52\tTime/batch 0.01\n",
      "Epoch: [44][399/469]\tLoss   0.35\tAcc  97.52\tTime/batch 0.01\n",
      "epoch 44\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [45][ 99/469]\tLoss   0.38\tAcc  97.44\tTime/batch 0.01\n",
      "Epoch: [45][199/469]\tLoss   0.36\tAcc  97.43\tTime/batch 0.01\n",
      "Epoch: [45][299/469]\tLoss   0.36\tAcc  97.45\tTime/batch 0.01\n",
      "Epoch: [45][399/469]\tLoss   0.37\tAcc  97.47\tTime/batch 0.01\n",
      "epoch 45\n",
      "Accuracy of the network on the 10000 test images: 97.0 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [46][ 99/469]\tLoss   0.35\tAcc  97.26\tTime/batch 0.01\n",
      "Epoch: [46][199/469]\tLoss   0.36\tAcc  97.41\tTime/batch 0.01\n",
      "Epoch: [46][299/469]\tLoss   0.36\tAcc  97.44\tTime/batch 0.01\n",
      "Epoch: [46][399/469]\tLoss   0.35\tAcc  97.41\tTime/batch 0.01\n",
      "epoch 46\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [47][ 99/469]\tLoss   0.35\tAcc  97.56\tTime/batch 0.01\n",
      "Epoch: [47][199/469]\tLoss   0.35\tAcc  97.57\tTime/batch 0.01\n",
      "Epoch: [47][299/469]\tLoss   0.36\tAcc  97.49\tTime/batch 0.01\n",
      "Epoch: [47][399/469]\tLoss   0.36\tAcc  97.44\tTime/batch 0.01\n",
      "epoch 47\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [48][ 99/469]\tLoss   0.30\tAcc  97.63\tTime/batch 0.01\n",
      "Epoch: [48][199/469]\tLoss   0.34\tAcc  97.56\tTime/batch 0.01\n",
      "Epoch: [48][299/469]\tLoss   0.35\tAcc  97.46\tTime/batch 0.01\n",
      "Epoch: [48][399/469]\tLoss   0.36\tAcc  97.43\tTime/batch 0.01\n",
      "epoch 48\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [49][ 99/469]\tLoss   0.35\tAcc  97.55\tTime/batch 0.01\n",
      "Epoch: [49][199/469]\tLoss   0.35\tAcc  97.54\tTime/batch 0.01\n",
      "Epoch: [49][299/469]\tLoss   0.37\tAcc  97.50\tTime/batch 0.01\n",
      "Epoch: [49][399/469]\tLoss   0.38\tAcc  97.46\tTime/batch 0.01\n",
      "epoch 49\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [50][ 99/469]\tLoss   0.35\tAcc  97.42\tTime/batch 0.01\n",
      "Epoch: [50][199/469]\tLoss   0.37\tAcc  97.38\tTime/batch 0.01\n",
      "Epoch: [50][299/469]\tLoss   0.38\tAcc  97.38\tTime/batch 0.01\n",
      "Epoch: [50][399/469]\tLoss   0.37\tAcc  97.42\tTime/batch 0.01\n",
      "epoch 50\n",
      "Accuracy of the network on the 10000 test images: 97.1 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [51][ 99/469]\tLoss   0.35\tAcc  97.55\tTime/batch 0.01\n",
      "Epoch: [51][199/469]\tLoss   0.34\tAcc  97.57\tTime/batch 0.01\n",
      "Epoch: [51][299/469]\tLoss   0.32\tAcc  97.64\tTime/batch 0.01\n",
      "Epoch: [51][399/469]\tLoss   0.34\tAcc  97.55\tTime/batch 0.01\n",
      "epoch 51\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [52][ 99/469]\tLoss   0.33\tAcc  97.77\tTime/batch 0.01\n",
      "Epoch: [52][199/469]\tLoss   0.32\tAcc  97.68\tTime/batch 0.01\n",
      "Epoch: [52][299/469]\tLoss   0.34\tAcc  97.60\tTime/batch 0.01\n",
      "Epoch: [52][399/469]\tLoss   0.33\tAcc  97.59\tTime/batch 0.01\n",
      "epoch 52\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [53][ 99/469]\tLoss   0.34\tAcc  97.68\tTime/batch 0.01\n",
      "Epoch: [53][199/469]\tLoss   0.35\tAcc  97.55\tTime/batch 0.01\n",
      "Epoch: [53][299/469]\tLoss   0.35\tAcc  97.57\tTime/batch 0.01\n",
      "Epoch: [53][399/469]\tLoss   0.34\tAcc  97.54\tTime/batch 0.01\n",
      "epoch 53\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [54][ 99/469]\tLoss   0.38\tAcc  97.22\tTime/batch 0.01\n",
      "Epoch: [54][199/469]\tLoss   0.34\tAcc  97.39\tTime/batch 0.01\n",
      "Epoch: [54][299/469]\tLoss   0.35\tAcc  97.41\tTime/batch 0.01\n",
      "Epoch: [54][399/469]\tLoss   0.34\tAcc  97.49\tTime/batch 0.01\n",
      "epoch 54\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [55][ 99/469]\tLoss   0.33\tAcc  97.52\tTime/batch 0.01\n",
      "Epoch: [55][199/469]\tLoss   0.33\tAcc  97.54\tTime/batch 0.01\n",
      "Epoch: [55][299/469]\tLoss   0.33\tAcc  97.54\tTime/batch 0.01\n",
      "Epoch: [55][399/469]\tLoss   0.34\tAcc  97.56\tTime/batch 0.01\n",
      "epoch 55\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [56][ 99/469]\tLoss   0.37\tAcc  97.21\tTime/batch 0.01\n",
      "Epoch: [56][199/469]\tLoss   0.34\tAcc  97.48\tTime/batch 0.01\n",
      "Epoch: [56][299/469]\tLoss   0.34\tAcc  97.54\tTime/batch 0.01\n",
      "Epoch: [56][399/469]\tLoss   0.33\tAcc  97.61\tTime/batch 0.01\n",
      "epoch 56\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [57][ 99/469]\tLoss   0.31\tAcc  97.62\tTime/batch 0.01\n",
      "Epoch: [57][199/469]\tLoss   0.32\tAcc  97.67\tTime/batch 0.01\n",
      "Epoch: [57][299/469]\tLoss   0.35\tAcc  97.57\tTime/batch 0.01\n",
      "Epoch: [57][399/469]\tLoss   0.34\tAcc  97.59\tTime/batch 0.01\n",
      "epoch 57\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [58][ 99/469]\tLoss   0.34\tAcc  97.46\tTime/batch 0.01\n",
      "Epoch: [58][199/469]\tLoss   0.33\tAcc  97.53\tTime/batch 0.01\n",
      "Epoch: [58][299/469]\tLoss   0.34\tAcc  97.49\tTime/batch 0.01\n",
      "Epoch: [58][399/469]\tLoss   0.34\tAcc  97.52\tTime/batch 0.01\n",
      "epoch 58\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [59][ 99/469]\tLoss   0.35\tAcc  97.59\tTime/batch 0.01\n",
      "Epoch: [59][199/469]\tLoss   0.33\tAcc  97.60\tTime/batch 0.01\n",
      "Epoch: [59][299/469]\tLoss   0.32\tAcc  97.71\tTime/batch 0.01\n",
      "Epoch: [59][399/469]\tLoss   0.34\tAcc  97.64\tTime/batch 0.01\n",
      "epoch 59\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [60][ 99/469]\tLoss   0.31\tAcc  97.73\tTime/batch 0.01\n",
      "Epoch: [60][199/469]\tLoss   0.33\tAcc  97.62\tTime/batch 0.01\n",
      "Epoch: [60][299/469]\tLoss   0.32\tAcc  97.66\tTime/batch 0.01\n",
      "Epoch: [60][399/469]\tLoss   0.34\tAcc  97.56\tTime/batch 0.01\n",
      "epoch 60\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [61][ 99/469]\tLoss   0.32\tAcc  97.62\tTime/batch 0.01\n",
      "Epoch: [61][199/469]\tLoss   0.34\tAcc  97.59\tTime/batch 0.01\n",
      "Epoch: [61][299/469]\tLoss   0.32\tAcc  97.65\tTime/batch 0.01\n",
      "Epoch: [61][399/469]\tLoss   0.32\tAcc  97.61\tTime/batch 0.01\n",
      "epoch 61\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [62][ 99/469]\tLoss   0.32\tAcc  97.71\tTime/batch 0.01\n",
      "Epoch: [62][199/469]\tLoss   0.32\tAcc  97.69\tTime/batch 0.01\n",
      "Epoch: [62][299/469]\tLoss   0.32\tAcc  97.64\tTime/batch 0.01\n",
      "Epoch: [62][399/469]\tLoss   0.32\tAcc  97.65\tTime/batch 0.01\n",
      "epoch 62\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [63][ 99/469]\tLoss   0.31\tAcc  97.73\tTime/batch 0.01\n",
      "Epoch: [63][199/469]\tLoss   0.31\tAcc  97.77\tTime/batch 0.01\n",
      "Epoch: [63][299/469]\tLoss   0.32\tAcc  97.66\tTime/batch 0.01\n",
      "Epoch: [63][399/469]\tLoss   0.33\tAcc  97.62\tTime/batch 0.01\n",
      "epoch 63\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [64][ 99/469]\tLoss   0.27\tAcc  97.88\tTime/batch 0.01\n",
      "Epoch: [64][199/469]\tLoss   0.27\tAcc  97.86\tTime/batch 0.01\n",
      "Epoch: [64][299/469]\tLoss   0.30\tAcc  97.73\tTime/batch 0.01\n",
      "Epoch: [64][399/469]\tLoss   0.32\tAcc  97.67\tTime/batch 0.01\n",
      "epoch 64\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [65][ 99/469]\tLoss   0.34\tAcc  97.52\tTime/batch 0.01\n",
      "Epoch: [65][199/469]\tLoss   0.31\tAcc  97.66\tTime/batch 0.01\n",
      "Epoch: [65][299/469]\tLoss   0.32\tAcc  97.65\tTime/batch 0.01\n",
      "Epoch: [65][399/469]\tLoss   0.32\tAcc  97.62\tTime/batch 0.01\n",
      "epoch 65\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [66][ 99/469]\tLoss   0.34\tAcc  97.53\tTime/batch 0.01\n",
      "Epoch: [66][199/469]\tLoss   0.34\tAcc  97.53\tTime/batch 0.01\n",
      "Epoch: [66][299/469]\tLoss   0.33\tAcc  97.54\tTime/batch 0.01\n",
      "Epoch: [66][399/469]\tLoss   0.33\tAcc  97.52\tTime/batch 0.01\n",
      "epoch 66\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [67][ 99/469]\tLoss   0.31\tAcc  97.75\tTime/batch 0.01\n",
      "Epoch: [67][199/469]\tLoss   0.33\tAcc  97.62\tTime/batch 0.01\n",
      "Epoch: [67][299/469]\tLoss   0.34\tAcc  97.55\tTime/batch 0.01\n",
      "Epoch: [67][399/469]\tLoss   0.34\tAcc  97.54\tTime/batch 0.01\n",
      "epoch 67\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [68][ 99/469]\tLoss   0.35\tAcc  97.50\tTime/batch 0.01\n",
      "Epoch: [68][199/469]\tLoss   0.34\tAcc  97.46\tTime/batch 0.01\n",
      "Epoch: [68][299/469]\tLoss   0.35\tAcc  97.47\tTime/batch 0.01\n",
      "Epoch: [68][399/469]\tLoss   0.35\tAcc  97.52\tTime/batch 0.01\n",
      "epoch 68\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [69][ 99/469]\tLoss   0.36\tAcc  97.60\tTime/batch 0.01\n",
      "Epoch: [69][199/469]\tLoss   0.35\tAcc  97.61\tTime/batch 0.01\n",
      "Epoch: [69][299/469]\tLoss   0.33\tAcc  97.64\tTime/batch 0.01\n",
      "Epoch: [69][399/469]\tLoss   0.33\tAcc  97.59\tTime/batch 0.01\n",
      "epoch 69\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [70][ 99/469]\tLoss   0.32\tAcc  97.70\tTime/batch 0.01\n",
      "Epoch: [70][199/469]\tLoss   0.34\tAcc  97.66\tTime/batch 0.01\n",
      "Epoch: [70][299/469]\tLoss   0.36\tAcc  97.60\tTime/batch 0.01\n",
      "Epoch: [70][399/469]\tLoss   0.35\tAcc  97.58\tTime/batch 0.01\n",
      "epoch 70\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [71][ 99/469]\tLoss   0.32\tAcc  97.67\tTime/batch 0.01\n",
      "Epoch: [71][199/469]\tLoss   0.32\tAcc  97.61\tTime/batch 0.01\n",
      "Epoch: [71][299/469]\tLoss   0.32\tAcc  97.58\tTime/batch 0.01\n",
      "Epoch: [71][399/469]\tLoss   0.33\tAcc  97.56\tTime/batch 0.01\n",
      "epoch 71\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [72][ 99/469]\tLoss   0.30\tAcc  97.71\tTime/batch 0.01\n",
      "Epoch: [72][199/469]\tLoss   0.32\tAcc  97.71\tTime/batch 0.01\n",
      "Epoch: [72][299/469]\tLoss   0.31\tAcc  97.66\tTime/batch 0.01\n",
      "Epoch: [72][399/469]\tLoss   0.32\tAcc  97.64\tTime/batch 0.01\n",
      "epoch 72\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [73][ 99/469]\tLoss   0.34\tAcc  97.61\tTime/batch 0.01\n",
      "Epoch: [73][199/469]\tLoss   0.32\tAcc  97.62\tTime/batch 0.01\n",
      "Epoch: [73][299/469]\tLoss   0.31\tAcc  97.72\tTime/batch 0.01\n",
      "Epoch: [73][399/469]\tLoss   0.32\tAcc  97.67\tTime/batch 0.01\n",
      "epoch 73\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [74][ 99/469]\tLoss   0.28\tAcc  97.66\tTime/batch 0.01\n",
      "Epoch: [74][199/469]\tLoss   0.31\tAcc  97.63\tTime/batch 0.01\n",
      "Epoch: [74][299/469]\tLoss   0.31\tAcc  97.63\tTime/batch 0.01\n",
      "Epoch: [74][399/469]\tLoss   0.32\tAcc  97.66\tTime/batch 0.01\n",
      "epoch 74\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [75][ 99/469]\tLoss   0.32\tAcc  97.65\tTime/batch 0.01\n",
      "Epoch: [75][199/469]\tLoss   0.34\tAcc  97.59\tTime/batch 0.01\n",
      "Epoch: [75][299/469]\tLoss   0.33\tAcc  97.62\tTime/batch 0.01\n",
      "Epoch: [75][399/469]\tLoss   0.32\tAcc  97.64\tTime/batch 0.01\n",
      "epoch 75\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [76][ 99/469]\tLoss   0.34\tAcc  97.69\tTime/batch 0.01\n",
      "Epoch: [76][199/469]\tLoss   0.33\tAcc  97.70\tTime/batch 0.01\n",
      "Epoch: [76][299/469]\tLoss   0.31\tAcc  97.72\tTime/batch 0.01\n",
      "Epoch: [76][399/469]\tLoss   0.31\tAcc  97.66\tTime/batch 0.01\n",
      "epoch 76\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [77][ 99/469]\tLoss   0.33\tAcc  97.76\tTime/batch 0.01\n",
      "Epoch: [77][199/469]\tLoss   0.32\tAcc  97.64\tTime/batch 0.01\n",
      "Epoch: [77][299/469]\tLoss   0.33\tAcc  97.62\tTime/batch 0.01\n",
      "Epoch: [77][399/469]\tLoss   0.33\tAcc  97.60\tTime/batch 0.01\n",
      "epoch 77\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [78][ 99/469]\tLoss   0.36\tAcc  97.48\tTime/batch 0.01\n",
      "Epoch: [78][199/469]\tLoss   0.33\tAcc  97.59\tTime/batch 0.01\n",
      "Epoch: [78][299/469]\tLoss   0.31\tAcc  97.62\tTime/batch 0.01\n",
      "Epoch: [78][399/469]\tLoss   0.32\tAcc  97.62\tTime/batch 0.01\n",
      "epoch 78\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [79][ 99/469]\tLoss   0.32\tAcc  97.61\tTime/batch 0.01\n",
      "Epoch: [79][199/469]\tLoss   0.31\tAcc  97.70\tTime/batch 0.01\n",
      "Epoch: [79][299/469]\tLoss   0.31\tAcc  97.69\tTime/batch 0.01\n",
      "Epoch: [79][399/469]\tLoss   0.31\tAcc  97.67\tTime/batch 0.01\n",
      "epoch 79\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [80][ 99/469]\tLoss   0.32\tAcc  97.68\tTime/batch 0.01\n",
      "Epoch: [80][199/469]\tLoss   0.33\tAcc  97.72\tTime/batch 0.01\n",
      "Epoch: [80][299/469]\tLoss   0.32\tAcc  97.72\tTime/batch 0.01\n",
      "Epoch: [80][399/469]\tLoss   0.32\tAcc  97.71\tTime/batch 0.01\n",
      "epoch 80\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [81][ 99/469]\tLoss   0.32\tAcc  97.66\tTime/batch 0.01\n",
      "Epoch: [81][199/469]\tLoss   0.32\tAcc  97.68\tTime/batch 0.01\n",
      "Epoch: [81][299/469]\tLoss   0.32\tAcc  97.69\tTime/batch 0.01\n",
      "Epoch: [81][399/469]\tLoss   0.31\tAcc  97.71\tTime/batch 0.01\n",
      "epoch 81\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [82][ 99/469]\tLoss   0.32\tAcc  97.65\tTime/batch 0.01\n",
      "Epoch: [82][199/469]\tLoss   0.31\tAcc  97.66\tTime/batch 0.01\n",
      "Epoch: [82][299/469]\tLoss   0.34\tAcc  97.56\tTime/batch 0.01\n",
      "Epoch: [82][399/469]\tLoss   0.32\tAcc  97.62\tTime/batch 0.01\n",
      "epoch 82\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [83][ 99/469]\tLoss   0.29\tAcc  97.61\tTime/batch 0.01\n",
      "Epoch: [83][199/469]\tLoss   0.30\tAcc  97.77\tTime/batch 0.01\n",
      "Epoch: [83][299/469]\tLoss   0.31\tAcc  97.66\tTime/batch 0.01\n",
      "Epoch: [83][399/469]\tLoss   0.32\tAcc  97.66\tTime/batch 0.01\n",
      "epoch 83\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [84][ 99/469]\tLoss   0.36\tAcc  97.54\tTime/batch 0.01\n",
      "Epoch: [84][199/469]\tLoss   0.33\tAcc  97.62\tTime/batch 0.01\n",
      "Epoch: [84][299/469]\tLoss   0.33\tAcc  97.62\tTime/batch 0.01\n",
      "Epoch: [84][399/469]\tLoss   0.33\tAcc  97.62\tTime/batch 0.01\n",
      "epoch 84\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [85][ 99/469]\tLoss   0.33\tAcc  97.48\tTime/batch 0.01\n",
      "Epoch: [85][199/469]\tLoss   0.31\tAcc  97.66\tTime/batch 0.01\n",
      "Epoch: [85][299/469]\tLoss   0.32\tAcc  97.67\tTime/batch 0.01\n",
      "Epoch: [85][399/469]\tLoss   0.32\tAcc  97.70\tTime/batch 0.01\n",
      "epoch 85\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [86][ 99/469]\tLoss   0.31\tAcc  97.55\tTime/batch 0.01\n",
      "Epoch: [86][199/469]\tLoss   0.32\tAcc  97.52\tTime/batch 0.01\n",
      "Epoch: [86][299/469]\tLoss   0.31\tAcc  97.63\tTime/batch 0.01\n",
      "Epoch: [86][399/469]\tLoss   0.32\tAcc  97.62\tTime/batch 0.01\n",
      "epoch 86\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "Saving the trained model and states.\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [87][ 99/469]\tLoss   0.31\tAcc  97.63\tTime/batch 0.01\n",
      "Epoch: [87][199/469]\tLoss   0.31\tAcc  97.55\tTime/batch 0.01\n",
      "Epoch: [87][299/469]\tLoss   0.32\tAcc  97.64\tTime/batch 0.01\n",
      "Epoch: [87][399/469]\tLoss   0.32\tAcc  97.63\tTime/batch 0.01\n",
      "epoch 87\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [88][ 99/469]\tLoss   0.29\tAcc  97.81\tTime/batch 0.01\n",
      "Epoch: [88][199/469]\tLoss   0.29\tAcc  97.82\tTime/batch 0.01\n",
      "Epoch: [88][299/469]\tLoss   0.31\tAcc  97.73\tTime/batch 0.01\n",
      "Epoch: [88][399/469]\tLoss   0.31\tAcc  97.68\tTime/batch 0.01\n",
      "epoch 88\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [89][ 99/469]\tLoss   0.33\tAcc  97.54\tTime/batch 0.01\n",
      "Epoch: [89][199/469]\tLoss   0.31\tAcc  97.64\tTime/batch 0.01\n",
      "Epoch: [89][299/469]\tLoss   0.31\tAcc  97.71\tTime/batch 0.01\n",
      "Epoch: [89][399/469]\tLoss   0.33\tAcc  97.69\tTime/batch 0.01\n",
      "epoch 89\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [90][ 99/469]\tLoss   0.37\tAcc  97.61\tTime/batch 0.01\n",
      "Epoch: [90][199/469]\tLoss   0.34\tAcc  97.64\tTime/batch 0.01\n",
      "Epoch: [90][299/469]\tLoss   0.34\tAcc  97.61\tTime/batch 0.01\n",
      "Epoch: [90][399/469]\tLoss   0.32\tAcc  97.64\tTime/batch 0.01\n",
      "epoch 90\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [91][ 99/469]\tLoss   0.33\tAcc  97.63\tTime/batch 0.01\n",
      "Epoch: [91][199/469]\tLoss   0.34\tAcc  97.59\tTime/batch 0.01\n",
      "Epoch: [91][299/469]\tLoss   0.33\tAcc  97.64\tTime/batch 0.01\n",
      "Epoch: [91][399/469]\tLoss   0.33\tAcc  97.65\tTime/batch 0.01\n",
      "epoch 91\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [92][ 99/469]\tLoss   0.36\tAcc  97.41\tTime/batch 0.01\n",
      "Epoch: [92][199/469]\tLoss   0.33\tAcc  97.55\tTime/batch 0.01\n",
      "Epoch: [92][299/469]\tLoss   0.33\tAcc  97.58\tTime/batch 0.01\n",
      "Epoch: [92][399/469]\tLoss   0.32\tAcc  97.64\tTime/batch 0.01\n",
      "epoch 92\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [93][ 99/469]\tLoss   0.28\tAcc  97.70\tTime/batch 0.01\n",
      "Epoch: [93][199/469]\tLoss   0.30\tAcc  97.71\tTime/batch 0.01\n",
      "Epoch: [93][299/469]\tLoss   0.30\tAcc  97.73\tTime/batch 0.01\n",
      "Epoch: [93][399/469]\tLoss   0.32\tAcc  97.63\tTime/batch 0.01\n",
      "epoch 93\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [94][ 99/469]\tLoss   0.31\tAcc  97.68\tTime/batch 0.01\n",
      "Epoch: [94][199/469]\tLoss   0.33\tAcc  97.60\tTime/batch 0.01\n",
      "Epoch: [94][299/469]\tLoss   0.34\tAcc  97.62\tTime/batch 0.01\n",
      "Epoch: [94][399/469]\tLoss   0.32\tAcc  97.68\tTime/batch 0.01\n",
      "epoch 94\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [95][ 99/469]\tLoss   0.35\tAcc  97.49\tTime/batch 0.01\n",
      "Epoch: [95][199/469]\tLoss   0.35\tAcc  97.50\tTime/batch 0.01\n",
      "Epoch: [95][299/469]\tLoss   0.34\tAcc  97.55\tTime/batch 0.01\n",
      "Epoch: [95][399/469]\tLoss   0.33\tAcc  97.61\tTime/batch 0.01\n",
      "epoch 95\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [96][ 99/469]\tLoss   0.33\tAcc  97.54\tTime/batch 0.01\n",
      "Epoch: [96][199/469]\tLoss   0.32\tAcc  97.64\tTime/batch 0.01\n",
      "Epoch: [96][299/469]\tLoss   0.33\tAcc  97.57\tTime/batch 0.01\n",
      "Epoch: [96][399/469]\tLoss   0.33\tAcc  97.58\tTime/batch 0.01\n",
      "epoch 96\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [97][ 99/469]\tLoss   0.35\tAcc  97.51\tTime/batch 0.01\n",
      "Epoch: [97][199/469]\tLoss   0.33\tAcc  97.52\tTime/batch 0.01\n",
      "Epoch: [97][299/469]\tLoss   0.33\tAcc  97.57\tTime/batch 0.01\n",
      "Epoch: [97][399/469]\tLoss   0.33\tAcc  97.60\tTime/batch 0.01\n",
      "epoch 97\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [98][ 99/469]\tLoss   0.30\tAcc  97.81\tTime/batch 0.01\n",
      "Epoch: [98][199/469]\tLoss   0.30\tAcc  97.68\tTime/batch 0.01\n",
      "Epoch: [98][299/469]\tLoss   0.31\tAcc  97.64\tTime/batch 0.01\n",
      "Epoch: [98][399/469]\tLoss   0.32\tAcc  97.64\tTime/batch 0.01\n",
      "epoch 98\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [99][ 99/469]\tLoss   0.33\tAcc  97.55\tTime/batch 0.01\n",
      "Epoch: [99][199/469]\tLoss   0.33\tAcc  97.55\tTime/batch 0.01\n",
      "Epoch: [99][299/469]\tLoss   0.32\tAcc  97.61\tTime/batch 0.01\n",
      "Epoch: [99][399/469]\tLoss   0.33\tAcc  97.57\tTime/batch 0.01\n",
      "epoch 99\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 1e-07\n",
      "Epoch: [100][ 99/469]\tLoss   0.30\tAcc  97.71\tTime/batch 0.01\n",
      "Epoch: [100][199/469]\tLoss   0.31\tAcc  97.62\tTime/batch 0.01\n",
      "Epoch: [100][299/469]\tLoss   0.31\tAcc  97.60\tTime/batch 0.01\n",
      "Epoch: [100][399/469]\tLoss   0.33\tAcc  97.62\tTime/batch 0.01\n",
      "epoch 100\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = binary_VGG_small(num_classes=10).to(device)\n",
    "best_acc = 0.0\n",
    "while (best_acc <97.0):\n",
    "\n",
    "    criterion = (nn.CrossEntropyLoss().cuda() \n",
    "                if torch.cuda.is_available() else nn.CrossEntropyLoss())\n",
    "\n",
    "    best_model = copy.deepcopy(net.state_dict())\n",
    "    start_epoch =0\n",
    "    num_epoch = 100\n",
    "    initial_lr = 1e-0\n",
    "    weight_decay = 1e-3\n",
    "    last_epoch = -1\n",
    "    save = True\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(),\n",
    "                            lr = initial_lr,\n",
    "                            weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "    lr_decay_milestones = [5,10,20,30,40,50,60]\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "                                optimizer,\n",
    "                                milestones=lr_decay_milestones,\n",
    "                                gamma=0.1,\n",
    "                                last_epoch=last_epoch)\n",
    "\n",
    "\n",
    "    def sparsity(testloader, net, device):\n",
    "        num_out, num_high = [], []\n",
    "\n",
    "        def _report_sparsity(m):\n",
    "            classname = m.__class__.__name__\n",
    "            if isinstance(m, q.PGBinaryConv2d):\n",
    "                num_out.append(m.num_out)\n",
    "                num_high.append(m.num_high)\n",
    "\n",
    "        net.eval()\n",
    "        # initialize cnt_out, cnt_high\n",
    "        net.apply(_report_sparsity)\n",
    "        cnt_out = np.zeros(len(num_out))\n",
    "        cnt_high = np.zeros(len(num_high))\n",
    "        num_out, num_high = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = net(images)\n",
    "                \"\"\" calculate statistics per PG layer \"\"\"\n",
    "                net.apply(_report_sparsity)\n",
    "                cnt_out += np.array(num_out)\n",
    "                cnt_high += np.array(num_high)\n",
    "                num_out = []\n",
    "                num_high = []\n",
    "        print('Sparsity of the update phase: %.1f %%' %\n",
    "            (100.0-np.sum(cnt_high)*1.0/np.sum(cnt_out)*100.0))\n",
    "\n",
    "\n",
    "    def test_accu(testloader, net, device):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # switch the model to the evaluation mode\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100.0 * correct / total\n",
    "        print('Accuracy of the network on the 10000 test images: %.1f %%' % accuracy)\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "    for epoch in range(start_epoch,num_epoch): # loop over the dataset multiple times\n",
    "\n",
    "        # set printing functions\n",
    "        batch_time = util.AverageMeter('Time/batch', ':.2f')\n",
    "        losses = util.AverageMeter('Loss', ':6.2f')\n",
    "        top1 = util.AverageMeter('Acc', ':6.2f')\n",
    "        progress = util.ProgressMeter(\n",
    "                        len(trainloader),\n",
    "                        [losses, top1, batch_time],\n",
    "                        prefix=\"Epoch: [{}]\".format(epoch+1)\n",
    "                        )\n",
    "\n",
    "        # switch the model to the training mode\n",
    "        net.train()\n",
    "\n",
    "        print('current learning rate = {}'.format(optimizer.param_groups[0]['lr']))\n",
    "        \n",
    "        # each epoch\n",
    "        end = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # for name, param in net.named_parameters():\n",
    "            #     if 'threshold' in name:\n",
    "            #         loss += (0.00001 * 0.5 *\n",
    "            #                     torch.norm(param-args.gtarget) *\n",
    "            #                     torch.norm(param-args.gtarget))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            _, batch_predicted = torch.max(outputs.data, 1)\n",
    "            batch_accu = 100.0 * (batch_predicted == labels).sum().item() / labels.size(0)\n",
    "            losses.update(loss.item(), labels.size(0))\n",
    "            top1.update(batch_accu, labels.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % 100 == 99:    \n",
    "                # print statistics every 100 mini-batches each epoch\n",
    "                progress.display(i) # i = batch id in the epoch\n",
    "\n",
    "        # update the learning rate\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # print test accuracy every few epochs\n",
    "        if epoch % 1 == 0:\n",
    "            print('epoch {}'.format(epoch+1))\n",
    "            epoch_acc = test_accu(testloader, net, device)\n",
    "            # sparsity(testloader, net, device)\n",
    "            if epoch_acc >= best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(net.state_dict())\n",
    "                # save the model if required\n",
    "                if save:\n",
    "                    print(\"Saving the trained model and states.\")\n",
    "                    save_folder = os.path.join('save_MNIST_model')\n",
    "                    util.save_models(best_model, save_folder,\n",
    "                            suffix='-finetune')\n",
    "                    \"\"\"\n",
    "                    states = {'epoch':epoch+1, \n",
    "                                'optimizer':optimizer.state_dict(), \n",
    "                                'scheduler':scheduler.state_dict()}\n",
    "                    util.save_states(states, save_folder, suffix=_ARCH)\n",
    "                #     \"\"\"\n",
    "            print(\"The best test accuracy so far: {:.1f}\".format(best_acc))\n",
    "\n",
    "        if epoch == 70:\n",
    "            optimizer = optim.SGD(net.parameters(), lr=0.0000001, momentum=0.5, weight_decay=1e-3)\n",
    "            scheduler = None  # or a new one\n",
    "\n",
    "\n",
    "        # if epoch > 10 and epoch_acc < 20.0:\n",
    "        #     print('Early stopping as the accuracy is not good enough.')\n",
    "        #     break\n",
    "\n",
    "        # if epoch > 20 and epoch_acc < 94.0:\n",
    "        #     print('Early stopping as the accuracy is not good enough.')\n",
    "        #     break\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "356da6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the trained model and states.\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving the trained model and states.\")\n",
    "save_folder = os.path.join('save_MNIST_model')\n",
    "util.save_models(best_model, save_folder,\n",
    "    suffix='-finetune')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0483ae",
   "metadata": {},
   "source": [
    "### 1.4.1 Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f0b98644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output logits: tensor([[-22.0323, -32.0968,  21.1290,  82.4194,  71.6452,  67.0645, -84.8065,\n",
      "         101.0645,  96.8710, 177.9677]], device='cuda:0')\n",
      "Predicted class: 9\n"
     ]
    }
   ],
   "source": [
    "single_image_loader = DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "\n",
    "data_iter = iter(single_image_loader)\n",
    "x, y = next(data_iter)   # x: (1, 1, 28, 28), y: (1,)\n",
    "outputs = {}\n",
    "\n",
    "# --- 3. Plot it ---\n",
    "plt.imshow(x[0][0], cmap='gray')\n",
    "plt.title(f\"Label: {y.item()}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# --- 4. Send to device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "# --- 5. Forward through model ---\n",
    "with torch.no_grad():\n",
    "    output = net(x)\n",
    "\n",
    "print(\"Output logits:\", output)\n",
    "print(\"Predicted class:\", torch.argmax(output, dim=1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "83c65671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  0.7419],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000,  1.0000,  1.0000],\n",
      "          [-1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [-1.0000, -1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000,  1.0000,  1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000, -1.0000, -1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000, -1.0000, -1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000, -1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000, -1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000, -1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [ 1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [ 1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [ 1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000,  0.4194, -0.7419,  ..., -0.7419, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000,  0.4194, -0.7419,  ..., -0.7419, -1.0000, -1.0000],\n",
      "          [-1.0000,  1.0000,  1.0000,  ...,  1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]]],\n",
      "       device='cuda:0', grad_fn=<QuantSignBackward>)\n"
     ]
    }
   ],
   "source": [
    "x, _ = next(iter(single_image_loader))\n",
    "x = x.to(device)\n",
    "features = net.forward_until(x, stop='conv2')\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57256440",
   "metadata": {},
   "source": [
    "## 1.5 CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72a1e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class binary_VGG_small(nn.Module):\n",
    "    def __init__(self, num_classes=10, batch_size=128):\n",
    "        super(binary_VGG_small, self).__init__()\n",
    "\n",
    "        ''' The input layer is binarized! '''\n",
    "        self.conv1 =  q.BinaryConv2d(24, 64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv2 = q.BinaryConv2d(64, 96, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv3 = q.BinaryConv2d(96, 96, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv4 = q.BinaryConv2d(96, 128, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv5 = q.BinaryConv2d(128, 192, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.binarize = q.QuantSign.apply\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = q.BinaryLinear(192*2*2, 256)\n",
    "        self.linear2 = q.BinaryLinear(192*2*2,num_classes)\n",
    "        num_gpus = 1\n",
    "        assert batch_size % num_gpus == 0, \\\n",
    "            \"Given batch size cannot evenly distributed to available gpus.\"\n",
    "        N = batch_size // num_gpus\n",
    "\n",
    "        self.encoder = q.InputEncoder(input_size=(1,3,32,32), resolution=32) # 255/32=8 -> from 1 channel becomes 8 channel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.binarize(self.conv1(x))\n",
    "        x = self.binarize(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.binarize(x)\n",
    "        x = self.binarize(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.binarize(x)\n",
    "        x = self.binarize(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.binarize(x)\n",
    "        x = self.binarize(self.conv5(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.binarize(x)\n",
    "        x = self.flatten(x)\n",
    "        out = self.linear2(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def forward_until(self, x, stop='conv2'):\n",
    "        x = self.encoder(x)\n",
    "        x = self.binarize(self.conv1(x))\n",
    "        if stop == 'conv1': return x\n",
    "        x = self.binarize(self.conv2(x))\n",
    "        if stop == 'conv2': return x\n",
    "        x = self.pool(x)\n",
    "        if stop == 'pool1': return x\n",
    "        x = self.binarize(self.conv3(x))\n",
    "        if stop == 'conv3': return x\n",
    "        x = self.pool(x)\n",
    "        x = self.binarize(x)\n",
    "        if stop == 'pool2': return x\n",
    "        x = self.flatten(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25124a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current learning rate = 10.0\n",
      "Epoch: [1][ 99/391]\tLoss 129.43\tAcc   9.58\tTime/batch 0.03\n",
      "Epoch: [1][199/391]\tLoss  95.26\tAcc  10.07\tTime/batch 0.03\n",
      "Epoch: [1][299/391]\tLoss  81.66\tAcc  10.16\tTime/batch 0.03\n",
      "epoch 1\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 10.0\n",
      "current learning rate = 10.0\n",
      "Epoch: [2][ 99/391]\tLoss  50.73\tAcc  10.46\tTime/batch 0.03\n",
      "Epoch: [2][199/391]\tLoss  52.02\tAcc  10.52\tTime/batch 0.03\n",
      "Epoch: [2][299/391]\tLoss  52.46\tAcc  10.43\tTime/batch 0.03\n",
      "epoch 2\n",
      "Accuracy of the network on the 10000 test images: 11.4 %\n",
      "The best test accuracy so far: 11.4\n",
      "current learning rate = 1.0\n",
      "Epoch: [3][ 99/391]\tLoss  20.74\tAcc  10.48\tTime/batch 0.03\n",
      "Epoch: [3][199/391]\tLoss  24.91\tAcc  10.29\tTime/batch 0.03\n",
      "Epoch: [3][299/391]\tLoss  27.16\tAcc  10.34\tTime/batch 0.03\n",
      "epoch 3\n",
      "Accuracy of the network on the 10000 test images: 11.6 %\n",
      "The best test accuracy so far: 11.6\n",
      "current learning rate = 1.0\n",
      "Epoch: [4][ 99/391]\tLoss  31.26\tAcc  10.54\tTime/batch 0.03\n",
      "Epoch: [4][199/391]\tLoss  30.11\tAcc  10.31\tTime/batch 0.03\n",
      "Epoch: [4][299/391]\tLoss  31.02\tAcc  10.65\tTime/batch 0.03\n",
      "epoch 4\n",
      "Accuracy of the network on the 10000 test images: 9.9 %\n",
      "The best test accuracy so far: 11.6\n",
      "current learning rate = 0.1\n",
      "Epoch: [5][ 99/391]\tLoss  11.80\tAcc  12.31\tTime/batch 0.03\n",
      "Epoch: [5][199/391]\tLoss  11.99\tAcc  11.39\tTime/batch 0.03\n",
      "Epoch: [5][299/391]\tLoss  13.67\tAcc  10.71\tTime/batch 0.03\n",
      "epoch 5\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 11.6\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [6][ 99/391]\tLoss   8.46\tAcc  10.14\tTime/batch 0.03\n",
      "Epoch: [6][199/391]\tLoss   5.92\tAcc   9.99\tTime/batch 0.03\n",
      "Epoch: [6][299/391]\tLoss   5.23\tAcc  10.03\tTime/batch 0.03\n",
      "epoch 6\n",
      "Accuracy of the network on the 10000 test images: 13.4 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [7][ 99/391]\tLoss   4.95\tAcc  10.68\tTime/batch 0.03\n",
      "Epoch: [7][199/391]\tLoss   4.42\tAcc  10.52\tTime/batch 0.03\n",
      "Epoch: [7][299/391]\tLoss   4.36\tAcc  10.42\tTime/batch 0.03\n",
      "epoch 7\n",
      "Accuracy of the network on the 10000 test images: 11.2 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [8][ 99/391]\tLoss   3.97\tAcc  10.85\tTime/batch 0.03\n",
      "Epoch: [8][199/391]\tLoss   3.94\tAcc  10.39\tTime/batch 0.03\n",
      "Epoch: [8][299/391]\tLoss   4.17\tAcc  10.42\tTime/batch 0.03\n",
      "epoch 8\n",
      "Accuracy of the network on the 10000 test images: 9.6 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [9][ 99/391]\tLoss   3.66\tAcc   9.83\tTime/batch 0.03\n",
      "Epoch: [9][199/391]\tLoss   4.42\tAcc   9.83\tTime/batch 0.03\n",
      "Epoch: [9][299/391]\tLoss   4.15\tAcc  10.23\tTime/batch 0.03\n",
      "epoch 9\n",
      "Accuracy of the network on the 10000 test images: 10.8 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.010000000000000002\n",
      "Epoch: [10][ 99/391]\tLoss   4.71\tAcc  10.19\tTime/batch 0.03\n",
      "Epoch: [10][199/391]\tLoss   4.38\tAcc  10.14\tTime/batch 0.03\n",
      "Epoch: [10][299/391]\tLoss   4.04\tAcc  10.17\tTime/batch 0.03\n",
      "epoch 10\n",
      "Accuracy of the network on the 10000 test images: 9.8 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [11][ 99/391]\tLoss   2.78\tAcc  10.02\tTime/batch 0.03\n",
      "Epoch: [11][199/391]\tLoss   3.16\tAcc   9.60\tTime/batch 0.03\n",
      "Epoch: [11][299/391]\tLoss   2.99\tAcc   9.69\tTime/batch 0.03\n",
      "epoch 11\n",
      "Accuracy of the network on the 10000 test images: 9.9 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [12][ 99/391]\tLoss   2.46\tAcc  10.23\tTime/batch 0.03\n",
      "Epoch: [12][199/391]\tLoss   2.44\tAcc  10.21\tTime/batch 0.03\n",
      "Epoch: [12][299/391]\tLoss   2.50\tAcc  10.17\tTime/batch 0.03\n",
      "epoch 12\n",
      "Accuracy of the network on the 10000 test images: 9.4 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [13][ 99/391]\tLoss   2.67\tAcc   9.97\tTime/batch 0.03\n",
      "Epoch: [13][199/391]\tLoss   2.54\tAcc   9.78\tTime/batch 0.03\n",
      "Epoch: [13][299/391]\tLoss   2.50\tAcc   9.88\tTime/batch 0.03\n",
      "epoch 13\n",
      "Accuracy of the network on the 10000 test images: 9.8 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [14][ 99/391]\tLoss   2.51\tAcc  10.06\tTime/batch 0.03\n",
      "Epoch: [14][199/391]\tLoss   2.43\tAcc  10.17\tTime/batch 0.03\n",
      "Epoch: [14][299/391]\tLoss   2.46\tAcc   9.96\tTime/batch 0.03\n",
      "epoch 14\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.0010000000000000002\n",
      "Epoch: [15][ 99/391]\tLoss   2.49\tAcc  10.43\tTime/batch 0.03\n",
      "Epoch: [15][199/391]\tLoss   2.48\tAcc  10.12\tTime/batch 0.03\n",
      "Epoch: [15][299/391]\tLoss   2.47\tAcc   9.97\tTime/batch 0.03\n",
      "epoch 15\n",
      "Accuracy of the network on the 10000 test images: 10.1 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [16][ 99/391]\tLoss   3.54\tAcc  10.41\tTime/batch 0.03\n",
      "Epoch: [16][199/391]\tLoss   2.95\tAcc   9.98\tTime/batch 0.03\n",
      "Epoch: [16][299/391]\tLoss   2.74\tAcc   9.96\tTime/batch 0.03\n",
      "epoch 16\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [17][ 99/391]\tLoss   2.32\tAcc  10.23\tTime/batch 0.03\n",
      "Epoch: [17][199/391]\tLoss   2.32\tAcc  10.16\tTime/batch 0.03\n",
      "Epoch: [17][299/391]\tLoss   2.32\tAcc  10.07\tTime/batch 0.03\n",
      "epoch 17\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [18][ 99/391]\tLoss   2.36\tAcc  10.07\tTime/batch 0.03\n",
      "Epoch: [18][199/391]\tLoss   2.34\tAcc  10.03\tTime/batch 0.03\n",
      "Epoch: [18][299/391]\tLoss   2.33\tAcc   9.93\tTime/batch 0.03\n",
      "epoch 18\n",
      "Accuracy of the network on the 10000 test images: 10.1 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [19][ 99/391]\tLoss   2.32\tAcc  10.25\tTime/batch 0.03\n",
      "Epoch: [19][199/391]\tLoss   2.32\tAcc  10.23\tTime/batch 0.03\n",
      "Epoch: [19][299/391]\tLoss   2.32\tAcc  10.11\tTime/batch 0.03\n",
      "epoch 19\n",
      "Accuracy of the network on the 10000 test images: 10.1 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 0.00010000000000000003\n",
      "Epoch: [20][ 99/391]\tLoss   2.33\tAcc   9.56\tTime/batch 0.03\n",
      "Epoch: [20][199/391]\tLoss   2.33\tAcc   9.93\tTime/batch 0.03\n",
      "Epoch: [20][299/391]\tLoss   2.33\tAcc  10.01\tTime/batch 0.03\n",
      "epoch 20\n",
      "Accuracy of the network on the 10000 test images: 10.1 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [21][ 99/391]\tLoss   2.31\tAcc  10.22\tTime/batch 0.03\n",
      "Epoch: [21][199/391]\tLoss   2.31\tAcc  10.09\tTime/batch 0.03\n",
      "Epoch: [21][299/391]\tLoss   2.31\tAcc  10.05\tTime/batch 0.03\n",
      "epoch 21\n",
      "Accuracy of the network on the 10000 test images: 10.1 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [22][ 99/391]\tLoss   2.31\tAcc  10.16\tTime/batch 0.03\n",
      "Epoch: [22][199/391]\tLoss   2.31\tAcc  10.15\tTime/batch 0.03\n",
      "Epoch: [22][299/391]\tLoss   2.31\tAcc  10.07\tTime/batch 0.03\n",
      "epoch 22\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [23][ 99/391]\tLoss   2.31\tAcc   9.95\tTime/batch 0.03\n",
      "Epoch: [23][199/391]\tLoss   2.31\tAcc   9.95\tTime/batch 0.03\n",
      "Epoch: [23][299/391]\tLoss   2.31\tAcc   9.92\tTime/batch 0.03\n",
      "epoch 23\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [24][ 99/391]\tLoss   2.31\tAcc  10.49\tTime/batch 0.03\n",
      "Epoch: [24][199/391]\tLoss   2.31\tAcc  10.09\tTime/batch 0.03\n",
      "Epoch: [24][299/391]\tLoss   2.31\tAcc   9.90\tTime/batch 0.03\n",
      "epoch 24\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000004e-05\n",
      "Epoch: [25][ 99/391]\tLoss   2.31\tAcc  10.02\tTime/batch 0.03\n",
      "Epoch: [25][199/391]\tLoss   2.31\tAcc  10.04\tTime/batch 0.03\n",
      "Epoch: [25][299/391]\tLoss   2.31\tAcc  10.01\tTime/batch 0.03\n",
      "epoch 25\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [26][ 99/391]\tLoss   2.31\tAcc   9.65\tTime/batch 0.03\n",
      "Epoch: [26][199/391]\tLoss   2.31\tAcc   9.77\tTime/batch 0.03\n",
      "Epoch: [26][299/391]\tLoss   2.31\tAcc  10.01\tTime/batch 0.03\n",
      "epoch 26\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [27][ 99/391]\tLoss   2.31\tAcc  10.12\tTime/batch 0.03\n",
      "Epoch: [27][199/391]\tLoss   2.31\tAcc  10.10\tTime/batch 0.03\n",
      "Epoch: [27][299/391]\tLoss   2.31\tAcc  10.06\tTime/batch 0.03\n",
      "epoch 27\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [28][ 99/391]\tLoss   2.31\tAcc  10.37\tTime/batch 0.03\n",
      "Epoch: [28][199/391]\tLoss   2.31\tAcc  10.16\tTime/batch 0.03\n",
      "Epoch: [28][299/391]\tLoss   2.31\tAcc  10.10\tTime/batch 0.03\n",
      "epoch 28\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [29][ 99/391]\tLoss   2.31\tAcc   9.95\tTime/batch 0.03\n",
      "Epoch: [29][199/391]\tLoss   2.31\tAcc  10.05\tTime/batch 0.03\n",
      "Epoch: [29][299/391]\tLoss   2.31\tAcc  10.06\tTime/batch 0.03\n",
      "epoch 29\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000004e-06\n",
      "Epoch: [30][ 99/391]\tLoss   2.31\tAcc   9.81\tTime/batch 0.03\n",
      "Epoch: [30][199/391]\tLoss   2.31\tAcc   9.86\tTime/batch 0.03\n",
      "Epoch: [30][299/391]\tLoss   2.31\tAcc   9.90\tTime/batch 0.03\n",
      "epoch 30\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [31][ 99/391]\tLoss   2.31\tAcc  10.38\tTime/batch 0.03\n",
      "Epoch: [31][199/391]\tLoss   2.31\tAcc  10.24\tTime/batch 0.03\n",
      "Epoch: [31][299/391]\tLoss   2.31\tAcc  10.07\tTime/batch 0.03\n",
      "epoch 31\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [32][ 99/391]\tLoss   2.31\tAcc   9.98\tTime/batch 0.03\n",
      "Epoch: [32][199/391]\tLoss   2.31\tAcc  10.20\tTime/batch 0.03\n",
      "Epoch: [32][299/391]\tLoss   2.31\tAcc  10.05\tTime/batch 0.03\n",
      "epoch 32\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [33][ 99/391]\tLoss   2.31\tAcc   9.67\tTime/batch 0.03\n",
      "Epoch: [33][199/391]\tLoss   2.31\tAcc   9.89\tTime/batch 0.03\n",
      "Epoch: [33][299/391]\tLoss   2.31\tAcc   9.93\tTime/batch 0.03\n",
      "epoch 33\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [34][ 99/391]\tLoss   2.31\tAcc   9.80\tTime/batch 0.03\n",
      "Epoch: [34][199/391]\tLoss   2.31\tAcc   9.89\tTime/batch 0.03\n",
      "Epoch: [34][299/391]\tLoss   2.31\tAcc   9.96\tTime/batch 0.03\n",
      "epoch 34\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [35][ 99/391]\tLoss   2.31\tAcc   9.59\tTime/batch 0.03\n",
      "Epoch: [35][199/391]\tLoss   2.31\tAcc   9.71\tTime/batch 0.03\n",
      "Epoch: [35][299/391]\tLoss   2.31\tAcc   9.88\tTime/batch 0.03\n",
      "epoch 35\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [36][ 99/391]\tLoss   2.31\tAcc  10.30\tTime/batch 0.03\n",
      "Epoch: [36][199/391]\tLoss   2.31\tAcc  10.10\tTime/batch 0.03\n",
      "Epoch: [36][299/391]\tLoss   2.31\tAcc   9.97\tTime/batch 0.03\n",
      "epoch 36\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [37][ 99/391]\tLoss   2.31\tAcc   9.91\tTime/batch 0.03\n",
      "Epoch: [37][199/391]\tLoss   2.31\tAcc  10.28\tTime/batch 0.03\n",
      "Epoch: [37][299/391]\tLoss   2.31\tAcc  10.16\tTime/batch 0.03\n",
      "epoch 37\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [38][ 99/391]\tLoss   2.31\tAcc  10.16\tTime/batch 0.03\n",
      "Epoch: [38][199/391]\tLoss   2.31\tAcc   9.97\tTime/batch 0.03\n",
      "Epoch: [38][299/391]\tLoss   2.31\tAcc  10.06\tTime/batch 0.03\n",
      "epoch 38\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [39][ 99/391]\tLoss   2.31\tAcc   9.92\tTime/batch 0.03\n",
      "Epoch: [39][199/391]\tLoss   2.31\tAcc   9.86\tTime/batch 0.03\n",
      "Epoch: [39][299/391]\tLoss   2.31\tAcc  10.00\tTime/batch 0.03\n",
      "epoch 39\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-07\n",
      "Epoch: [40][ 99/391]\tLoss   2.31\tAcc   9.75\tTime/batch 0.03\n",
      "Epoch: [40][199/391]\tLoss   2.31\tAcc   9.96\tTime/batch 0.03\n",
      "Epoch: [40][299/391]\tLoss   2.31\tAcc   9.94\tTime/batch 0.03\n",
      "epoch 40\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-08\n",
      "Epoch: [41][ 99/391]\tLoss   2.31\tAcc  10.52\tTime/batch 0.03\n",
      "Epoch: [41][199/391]\tLoss   2.31\tAcc  10.09\tTime/batch 0.03\n",
      "Epoch: [41][299/391]\tLoss   2.31\tAcc  10.01\tTime/batch 0.03\n",
      "epoch 41\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-08\n",
      "Epoch: [42][ 99/391]\tLoss   2.31\tAcc   9.88\tTime/batch 0.03\n",
      "Epoch: [42][199/391]\tLoss   2.31\tAcc   9.88\tTime/batch 0.03\n",
      "Epoch: [42][299/391]\tLoss   2.31\tAcc   9.93\tTime/batch 0.03\n",
      "epoch 42\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-08\n",
      "Epoch: [43][ 99/391]\tLoss   2.31\tAcc  10.16\tTime/batch 0.03\n",
      "Epoch: [43][199/391]\tLoss   2.31\tAcc  10.06\tTime/batch 0.03\n",
      "Epoch: [43][299/391]\tLoss   2.31\tAcc  10.08\tTime/batch 0.03\n",
      "epoch 43\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-08\n",
      "Epoch: [44][ 99/391]\tLoss   2.31\tAcc   9.96\tTime/batch 0.03\n",
      "Epoch: [44][199/391]\tLoss   2.31\tAcc   9.96\tTime/batch 0.03\n",
      "Epoch: [44][299/391]\tLoss   2.31\tAcc  10.10\tTime/batch 0.03\n",
      "epoch 44\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-08\n",
      "Epoch: [45][ 99/391]\tLoss   2.31\tAcc   9.73\tTime/batch 0.03\n",
      "Epoch: [45][199/391]\tLoss   2.31\tAcc  10.03\tTime/batch 0.03\n",
      "Epoch: [45][299/391]\tLoss   2.31\tAcc  10.20\tTime/batch 0.03\n",
      "epoch 45\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-08\n",
      "Epoch: [46][ 99/391]\tLoss   2.31\tAcc   9.79\tTime/batch 0.03\n",
      "Epoch: [46][199/391]\tLoss   2.31\tAcc  10.02\tTime/batch 0.03\n",
      "Epoch: [46][299/391]\tLoss   2.31\tAcc  10.01\tTime/batch 0.03\n",
      "epoch 46\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-08\n",
      "Epoch: [47][ 99/391]\tLoss   2.31\tAcc  10.20\tTime/batch 0.03\n",
      "Epoch: [47][199/391]\tLoss   2.31\tAcc  10.12\tTime/batch 0.03\n",
      "Epoch: [47][299/391]\tLoss   2.31\tAcc   9.95\tTime/batch 0.03\n",
      "epoch 47\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-08\n",
      "Epoch: [48][ 99/391]\tLoss   2.31\tAcc   9.84\tTime/batch 0.03\n",
      "Epoch: [48][199/391]\tLoss   2.31\tAcc   9.79\tTime/batch 0.03\n",
      "Epoch: [48][299/391]\tLoss   2.31\tAcc  10.10\tTime/batch 0.03\n",
      "epoch 48\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-08\n",
      "Epoch: [49][ 99/391]\tLoss   2.31\tAcc   9.85\tTime/batch 0.03\n",
      "Epoch: [49][199/391]\tLoss   2.31\tAcc   9.89\tTime/batch 0.03\n",
      "Epoch: [49][299/391]\tLoss   2.31\tAcc   9.91\tTime/batch 0.03\n",
      "epoch 49\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "current learning rate = 1.0000000000000005e-08\n",
      "Epoch: [50][ 99/391]\tLoss   2.31\tAcc   9.94\tTime/batch 0.03\n",
      "Epoch: [50][199/391]\tLoss   2.31\tAcc   9.84\tTime/batch 0.03\n",
      "Epoch: [50][299/391]\tLoss   2.31\tAcc  10.01\tTime/batch 0.03\n",
      "epoch 50\n",
      "Accuracy of the network on the 10000 test images: 10.0 %\n",
      "The best test accuracy so far: 13.4\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = binary_VGG_small(num_classes=10).to(device)\n",
    "\n",
    "criterion = (nn.CrossEntropyLoss().cuda() \n",
    "            if torch.cuda.is_available() else nn.CrossEntropyLoss())\n",
    "\n",
    "best_acc = 0.0\n",
    "best_model = copy.deepcopy(net.state_dict())\n",
    "start_epoch =0\n",
    "num_epoch = 50\n",
    "initial_lr = 1e1\n",
    "weight_decay = 1e-3\n",
    "last_epoch = -1\n",
    "save = False\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),\n",
    "                          lr = initial_lr,\n",
    "                          weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "lr_decay_milestones = [2,4,5,10,15,20,25,30,40]\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "                            optimizer,\n",
    "                            milestones=lr_decay_milestones,\n",
    "                            gamma=0.1,\n",
    "                            last_epoch=last_epoch)\n",
    "\n",
    "\n",
    "def sparsity(testloader, net, device):\n",
    "    num_out, num_high = [], []\n",
    "\n",
    "    def _report_sparsity(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if isinstance(m, q.PGBinaryConv2d):\n",
    "            num_out.append(m.num_out)\n",
    "            num_high.append(m.num_high)\n",
    "\n",
    "    net.eval()\n",
    "    # initialize cnt_out, cnt_high\n",
    "    net.apply(_report_sparsity)\n",
    "    cnt_out = np.zeros(len(num_out))\n",
    "    cnt_high = np.zeros(len(num_high))\n",
    "    num_out, num_high = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            \"\"\" calculate statistics per PG layer \"\"\"\n",
    "            net.apply(_report_sparsity)\n",
    "            cnt_out += np.array(num_out)\n",
    "            cnt_high += np.array(num_high)\n",
    "            num_out = []\n",
    "            num_high = []\n",
    "    print('Sparsity of the update phase: %.1f %%' %\n",
    "          (100.0-np.sum(cnt_high)*1.0/np.sum(cnt_out)*100.0))\n",
    "\n",
    "\n",
    "def test_accu(testloader, net, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # switch the model to the evaluation mode\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print('Accuracy of the network on the 10000 test images: %.1f %%' % accuracy)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch,num_epoch): # loop over the dataset multiple times\n",
    "\n",
    "    # set printing functions\n",
    "    batch_time = util.AverageMeter('Time/batch', ':.2f')\n",
    "    losses = util.AverageMeter('Loss', ':6.2f')\n",
    "    top1 = util.AverageMeter('Acc', ':6.2f')\n",
    "    progress = util.ProgressMeter(\n",
    "                    len(trainloader),\n",
    "                    [losses, top1, batch_time],\n",
    "                    prefix=\"Epoch: [{}]\".format(epoch+1)\n",
    "                    )\n",
    "\n",
    "    # switch the model to the training mode\n",
    "    net.train()\n",
    "\n",
    "    print('current learning rate = {}'.format(optimizer.param_groups[0]['lr']))\n",
    "    \n",
    "    # each epoch\n",
    "    end = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # for name, param in net.named_parameters():\n",
    "        #     if 'threshold' in name:\n",
    "        #         loss += (0.00001 * 0.5 *\n",
    "        #                     torch.norm(param-args.gtarget) *\n",
    "        #                     torch.norm(param-args.gtarget))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        _, batch_predicted = torch.max(outputs.data, 1)\n",
    "        batch_accu = 100.0 * (batch_predicted == labels).sum().item() / labels.size(0)\n",
    "        losses.update(loss.item(), labels.size(0))\n",
    "        top1.update(batch_accu, labels.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 99:    \n",
    "            # print statistics every 100 mini-batches each epoch\n",
    "            progress.display(i) # i = batch id in the epoch\n",
    "\n",
    "    # update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # print test accuracy every few epochs\n",
    "    if epoch % 1 == 0:\n",
    "        print('epoch {}'.format(epoch+1))\n",
    "        epoch_acc = test_accu(testloader, net, device)\n",
    "        # sparsity(testloader, net, device)\n",
    "        if epoch_acc >= best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model = copy.deepcopy(net.state_dict())\n",
    "        print(\"The best test accuracy so far: {:.1f}\".format(best_acc))\n",
    "\n",
    "        # save the model if required\n",
    "        if save:\n",
    "            print(\"Saving the trained model and states.\")\n",
    "            save_folder = os.path.join('save_MNIST_model')\n",
    "            util.save_models(best_model, save_folder,\n",
    "                    suffix='-finetune')\n",
    "            \"\"\"\n",
    "            states = {'epoch':epoch+1, \n",
    "                        'optimizer':optimizer.state_dict(), \n",
    "                        'scheduler':scheduler.state_dict()}\n",
    "            util.save_states(states, save_folder, suffix=_ARCH)\n",
    "        #     \"\"\"\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffcfec9",
   "metadata": {},
   "source": [
    "## 1.6 Component Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "733d5a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class thermal_encoder(nn.Module):\n",
    "    def __init__(self, num_classes=10, batch_size=128):\n",
    "        super(thermal_encoder, self).__init__()\n",
    "\n",
    "        ''' The input layer is binarized! '''\n",
    "        num_gpus = 1\n",
    "        assert batch_size % num_gpus == 0, \\\n",
    "            \"Given batch size cannot evenly distributed to available gpus.\"\n",
    "        N = batch_size // num_gpus\n",
    "\n",
    "        self.encoder = q.InputEncoder(input_size=(1,1,1,1), resolution=32) # 255/32=8 -> from 1 channel becomes 8 channel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        return out\n",
    "    \n",
    "encoder = thermal_encoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f3ef007f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test pixel value (0-255): 16\n",
      "Encoded pixel: tensor([[[[ 1.]],\n",
      "\n",
      "         [[-1.]],\n",
      "\n",
      "         [[-1.]],\n",
      "\n",
      "         [[-1.]],\n",
      "\n",
      "         [[-1.]],\n",
      "\n",
      "         [[-1.]],\n",
      "\n",
      "         [[-1.]],\n",
      "\n",
      "         [[-1.]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# create a single 1x1 tensor\n",
    "test_pixel = 16+32*0\n",
    "print(\"Test pixel value (0-255):\", test_pixel)\n",
    "\n",
    "test_pixel = torch.tensor([[[test_pixel/255]]]).to(device)\n",
    "encoded_pixel = encoder(test_pixel)\n",
    "print(\"Encoded pixel:\", encoded_pixel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
