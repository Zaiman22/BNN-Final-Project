{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf318e8-78e4-42c4-8e44-606ca5b81d80",
   "metadata": {},
   "source": [
    "# Brevitas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bec7a6-94b9-41a8-b445-7d977f71a661",
   "metadata": {},
   "source": [
    "## 1 Traditional Binary Neural Network (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86007cc-a84d-450b-b126-85b56ce5954e",
   "metadata": {},
   "source": [
    "### 1.1 Importing and checking hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "724a188a-fb28-4848-87d4-afc85901e7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.8.0+cu128\n",
      "Cuda is available: True\n",
      "device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for training model\n",
    "# import brevitas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch.optim as optim\n",
    "\n",
    "# fracbnn modules\n",
    "sys.path.append('./src')\n",
    "import utils as util\n",
    "import quantization as q\n",
    "\n",
    "\n",
    "# # for dataset\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Checking version\n",
    "print(f'Torch version: {torch.__version__}')\n",
    "# i dont get how to use brevitas, many other paper such as fracbnn and reacnet also did not use brevitas actually\n",
    "# print(f'Brevitas version: {brevitas.__version__}')\n",
    "\n",
    "\n",
    "# checking hardware\n",
    "# if torch.cuda.is_available():\n",
    "print(f'Cuda is available: {torch.cuda.is_available()}')  # should be True\n",
    "print(f'device: {torch.cuda.get_device_name(0)}')  # should say RTX 3060\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c61fa43",
   "metadata": {},
   "source": [
    "## 1.2 Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb781b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/home/jovyan/dataset'\n",
    "\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=dataset_dir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=dataset_dir,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3dc39c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(training_data, batch_size=256, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87fc33c",
   "metadata": {},
   "source": [
    "## 1.3 Binary Genetic algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53e0cf5",
   "metadata": {},
   "source": [
    "### 1.3.0 Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c11b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GA Helpers ---\n",
    "def generate_weight(x, y):\n",
    "    return 2 * torch.randint(0, 2, (x, y)) - 1  # -1 or 1\n",
    "\n",
    "def mutate_weight(weight, mutation_rate=0.2):\n",
    "    x, y = weight.shape\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            if random.random() < mutation_rate:\n",
    "                weight[i, j] *= -1\n",
    "    return weight\n",
    "\n",
    "def get_fitness(target, candidate):\n",
    "    # Fitness = number of matching elements\n",
    "    return torch.sum(target == candidate).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836121bd",
   "metadata": {},
   "source": [
    "### 1.3.1 Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0900164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: Best fitness = 8\n",
      "Generation 1: Best fitness = 8\n",
      "Generation 2: Best fitness = 8\n",
      "Generation 3: Best fitness = 9\n",
      "ðŸŽ¯ Found perfect match!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, -1,  1],\n",
      "        [-1,  1, -1],\n",
      "        [ 1, -1,  1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "initial_population = 50\n",
    "generations = 100\n",
    "mutation_rate = 0.1\n",
    "survivor =25\n",
    "\n",
    "\n",
    "\n",
    "# --- Target ---\n",
    "target_weight = torch.tensor([[1, -1, 1],\n",
    "                              [-1, 1, -1],\n",
    "                              [1, -1, 1]])\n",
    "\n",
    "# --- Step 1: Initialize population ---\n",
    "population = [generate_weight(3, 3) for _ in range(initial_population)]\n",
    "\n",
    "# --- GA Loop ---\n",
    "for gen in range(generations):\n",
    "    # Step 2: Evaluate fitness\n",
    "    fitness_scores = [get_fitness(target_weight, ind) for ind in population]\n",
    "    \n",
    "    # Step 3: Select best (elitism: keep top 2)\n",
    "    sorted_pop = [p for _, p in sorted(zip(fitness_scores, population), key=lambda x: x[0], reverse=True)]\n",
    "    best = sorted_pop[0]\n",
    "    best_fitness = max(fitness_scores)\n",
    "    \n",
    "    print(f\"Generation {gen}: Best fitness = {best_fitness}\")\n",
    "    \n",
    "    # Stop early if perfect solution found\n",
    "    if best_fitness == target_weight.numel():\n",
    "        print(\"ðŸŽ¯ Found perfect match!\")\n",
    "        break\n",
    "    \n",
    "    # Step 4: Create next generation (mutations of top parents)\n",
    "    new_population = []\n",
    "    for i in range(initial_population):\n",
    "        parent = random.choice(sorted_pop[:survivor]).clone()  # pick from top 5\n",
    "        child = mutate_weight(parent.clone(), mutation_rate)\n",
    "        new_population.append(child)\n",
    "    \n",
    "    population = new_population\n",
    "\n",
    "# --- Show best solution ---\n",
    "plt.imshow(best.numpy(), cmap=\"gray\", interpolation=\"nearest\")\n",
    "plt.colorbar(label=\"Weight Value\")\n",
    "plt.title(f\"Best Evolved Matrix (Fitness={best_fitness})\")\n",
    "plt.show()\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4edc8e",
   "metadata": {},
   "source": [
    "### 1.3.2 Multi channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49672738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: Best fitness = 29\n",
      "Generation 1: Best fitness = 31\n",
      "Generation 2: Best fitness = 35\n",
      "Generation 3: Best fitness = 36\n",
      "Generation 4: Best fitness = 36\n",
      "Generation 5: Best fitness = 37\n",
      "Generation 6: Best fitness = 39\n",
      "Generation 7: Best fitness = 40\n",
      "Generation 8: Best fitness = 40\n",
      "Generation 9: Best fitness = 40\n",
      "Generation 10: Best fitness = 40\n",
      "Generation 11: Best fitness = 41\n",
      "Generation 12: Best fitness = 41\n",
      "Generation 13: Best fitness = 41\n",
      "Generation 14: Best fitness = 41\n",
      "Generation 15: Best fitness = 41\n",
      "Generation 16: Best fitness = 41\n",
      "Generation 17: Best fitness = 41\n",
      "Generation 18: Best fitness = 42\n",
      "Generation 19: Best fitness = 42\n",
      "Generation 20: Best fitness = 42\n",
      "Generation 21: Best fitness = 42\n",
      "Generation 22: Best fitness = 42\n",
      "Generation 23: Best fitness = 42\n",
      "Generation 24: Best fitness = 42\n",
      "Generation 25: Best fitness = 43\n",
      "Generation 26: Best fitness = 43\n",
      "Generation 27: Best fitness = 43\n",
      "Generation 28: Best fitness = 43\n",
      "Generation 29: Best fitness = 43\n",
      "Generation 30: Best fitness = 43\n",
      "Generation 31: Best fitness = 43\n",
      "Generation 32: Best fitness = 43\n",
      "Generation 33: Best fitness = 43\n",
      "Generation 34: Best fitness = 43\n",
      "Generation 35: Best fitness = 43\n",
      "Generation 36: Best fitness = 43\n",
      "Generation 37: Best fitness = 43\n",
      "Generation 38: Best fitness = 45\n",
      "ðŸŽ¯ Found perfect match!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x1500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Multi channel target (5 channel)\n",
    "target_weight = torch.tensor([[[1, -1, 1],\n",
    "                              [-1, 1, -1],\n",
    "                              [1, -1, 1]],\n",
    "\n",
    "                              [[1, -1, 1],\n",
    "                              [1, -1, 1],\n",
    "                              [1, -1, 1]],\n",
    "\n",
    "                              [[1, 1, 1],\n",
    "                              [-1, -1, -1],\n",
    "                              [1, 1, 1]],\n",
    "\n",
    "                              [[-1, 1, 1],\n",
    "                              [1, -1, 1],\n",
    "                              [1, 1, -1]],\n",
    "\n",
    "                              [[1, 1, -1],\n",
    "                              [1, -1, 1],\n",
    "                              [-1, 1, 1]]\n",
    "                            \n",
    "                              ])\n",
    "\n",
    "num_channel = target_weight.shape[0]\n",
    "population  = 50\n",
    "generations = 1000\n",
    "\n",
    "weight = [torch.stack([generate_weight(3, 3) for _ in range(num_channel)]) for _ in range(population)]\n",
    "\n",
    "\n",
    "# --- GA Loop ---\n",
    "for gen in range(generations):\n",
    "    # Step 2: Evaluate fitness\n",
    "    # population loop\n",
    "    fitness_scores = []\n",
    "    for ind in weight:  # each individual is a tensor of shape [num_channel, 3, 3]\n",
    "        fitness = 0\n",
    "        for chann in range(num_channel):\n",
    "            fitness += get_fitness(target_weight[chann], ind[chann])\n",
    "        fitness_scores.append(fitness)\n",
    "\n",
    "    # Step 3: Select best (elitism: keep top 2)\n",
    "    sorted_pop = [p for _, p in sorted(zip(fitness_scores, weight), key=lambda x: x[0], reverse=True)]\n",
    "    best = sorted_pop[0]\n",
    "    best_fitness = max(fitness_scores)\n",
    "    \n",
    "    print(f\"Generation {gen}: Best fitness = {best_fitness}\")\n",
    "    \n",
    "    # Stop early if perfect solution found\n",
    "    if best_fitness == target_weight.numel():\n",
    "        print(\"ðŸŽ¯ Found perfect match!\")\n",
    "        break\n",
    "    \n",
    "    # Step 4: Create next generation (mutations of top parents)\n",
    "    # Step 4: Create next generation (mutations of top parents)\n",
    "    weight = []\n",
    "\n",
    "    for _ in range(population):\n",
    "        parent = random.choice(sorted_pop[:5]).clone()  # pick a top parent\n",
    "        child = torch.stack([mutate_weight(parent[ch], mutation_rate) for ch in range(num_channel)])\n",
    "        new_population.append(child)\n",
    "\n",
    "    weight = new_population\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(num_channel, 2, figsize=(6, 3 * num_channel))\n",
    "\n",
    "for ch in range(num_channel):\n",
    "    # Target\n",
    "    axes[ch, 0].imshow(target_weight[ch].numpy(), cmap=\"gray\", interpolation=\"nearest\")\n",
    "    axes[ch, 0].set_title(f\"Target (ch={ch})\")\n",
    "    axes[ch, 0].axis(\"off\")\n",
    "\n",
    "    # Best\n",
    "    axes[ch, 1].imshow(best[ch].numpy(), cmap=\"gray\", interpolation=\"nearest\")\n",
    "    axes[ch, 1].set_title(f\"Best (ch={ch})\")\n",
    "    axes[ch, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d85bd7",
   "metadata": {},
   "source": [
    "## 1.4 Creating VGG-16 binary code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25bfa7c",
   "metadata": {},
   "source": [
    "### 1.4.1 Initial VGG using binary weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5ff4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class binary_VGG_small(nn.Module):\n",
    "    def __init__(self, num_classes=10, batch_size=128):\n",
    "        super(binary_VGG_small, self).__init__()\n",
    "\n",
    "        ''' The input layer is binarized! '''\n",
    "        self.conv1 =  q.BinaryConv2d(32, 26, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv2 = q.BinaryConv2d(26, 24, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv3 = q.BinaryConv2d(24, 31, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv4 = q.BinaryConv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.binarize = q.QuantSign.apply\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(31*7*7, num_classes)\n",
    "        num_gpus = 1\n",
    "        assert batch_size % num_gpus == 0, \\\n",
    "            \"Given batch size cannot evenly distributed to available gpus.\"\n",
    "        N = batch_size // num_gpus\n",
    "\n",
    "        self.encoder = q.InputEncoder(input_size=(1,1,28,28), resolution=8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.binarize(self.conv1(x))\n",
    "        x = self.binarize(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.binarize(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        out = self.linear(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c949856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tensor([[ 0.4704, -0.0026,  0.3751, -2.0827,  0.0050,  0.2134,  0.8289, -0.4840,\n",
      "          0.6485,  0.1553]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = binary_VGG_small(num_classes=10).to(device)\n",
    "# put input on the same device\n",
    "input = torch.randn(1, 1, 28, 28).to(device)\n",
    "output = model(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb588b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current learning rate = 0.001\n",
      "Epoch: [1][ 99/235]\tLoss   0.85\tAcc  74.58\tTime/batch 0.02\n",
      "Epoch: [1][199/235]\tLoss   0.59\tAcc  82.37\tTime/batch 0.02\n",
      "epoch 1\n",
      "Accuracy of the network on the 10000 test images: 92.8 %\n",
      "The best test accuracy so far: 92.8\n",
      "current learning rate = 0.001\n",
      "Epoch: [2][ 99/235]\tLoss   0.25\tAcc  92.74\tTime/batch 0.02\n",
      "Epoch: [2][199/235]\tLoss   0.24\tAcc  92.82\tTime/batch 0.02\n",
      "epoch 2\n",
      "Accuracy of the network on the 10000 test images: 94.6 %\n",
      "The best test accuracy so far: 94.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [3][ 99/235]\tLoss   0.18\tAcc  94.59\tTime/batch 0.02\n",
      "Epoch: [3][199/235]\tLoss   0.17\tAcc  94.79\tTime/batch 0.02\n",
      "epoch 3\n",
      "Accuracy of the network on the 10000 test images: 95.8 %\n",
      "The best test accuracy so far: 95.8\n",
      "current learning rate = 0.001\n",
      "Epoch: [4][ 99/235]\tLoss   0.16\tAcc  95.28\tTime/batch 0.02\n",
      "Epoch: [4][199/235]\tLoss   0.15\tAcc  95.49\tTime/batch 0.02\n",
      "epoch 4\n",
      "Accuracy of the network on the 10000 test images: 95.9 %\n",
      "The best test accuracy so far: 95.9\n",
      "current learning rate = 0.001\n",
      "Epoch: [5][ 99/235]\tLoss   0.13\tAcc  95.95\tTime/batch 0.02\n",
      "Epoch: [5][199/235]\tLoss   0.13\tAcc  95.99\tTime/batch 0.02\n",
      "epoch 5\n",
      "Accuracy of the network on the 10000 test images: 96.5 %\n",
      "The best test accuracy so far: 96.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [6][ 99/235]\tLoss   0.12\tAcc  96.27\tTime/batch 0.02\n",
      "Epoch: [6][199/235]\tLoss   0.12\tAcc  96.28\tTime/batch 0.02\n",
      "epoch 6\n",
      "Accuracy of the network on the 10000 test images: 96.4 %\n",
      "The best test accuracy so far: 96.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [7][ 99/235]\tLoss   0.11\tAcc  96.76\tTime/batch 0.02\n",
      "Epoch: [7][199/235]\tLoss   0.11\tAcc  96.67\tTime/batch 0.02\n",
      "epoch 7\n",
      "Accuracy of the network on the 10000 test images: 97.0 %\n",
      "The best test accuracy so far: 97.0\n",
      "current learning rate = 0.001\n",
      "Epoch: [8][ 99/235]\tLoss   0.11\tAcc  96.70\tTime/batch 0.02\n",
      "Epoch: [8][199/235]\tLoss   0.11\tAcc  96.76\tTime/batch 0.02\n",
      "epoch 8\n",
      "Accuracy of the network on the 10000 test images: 96.9 %\n",
      "The best test accuracy so far: 97.0\n",
      "current learning rate = 0.001\n",
      "Epoch: [9][ 99/235]\tLoss   0.11\tAcc  96.77\tTime/batch 0.02\n",
      "Epoch: [9][199/235]\tLoss   0.10\tAcc  96.85\tTime/batch 0.02\n",
      "epoch 9\n",
      "Accuracy of the network on the 10000 test images: 96.8 %\n",
      "The best test accuracy so far: 97.0\n",
      "current learning rate = 0.001\n",
      "Epoch: [10][ 99/235]\tLoss   0.09\tAcc  97.15\tTime/batch 0.02\n",
      "Epoch: [10][199/235]\tLoss   0.10\tAcc  96.79\tTime/batch 0.02\n",
      "epoch 10\n",
      "Accuracy of the network on the 10000 test images: 96.9 %\n",
      "The best test accuracy so far: 97.0\n",
      "current learning rate = 0.001\n",
      "Epoch: [11][ 99/235]\tLoss   0.10\tAcc  96.91\tTime/batch 0.02\n",
      "Epoch: [11][199/235]\tLoss   0.10\tAcc  97.00\tTime/batch 0.02\n",
      "epoch 11\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 0.001\n",
      "Epoch: [12][ 99/235]\tLoss   0.10\tAcc  97.02\tTime/batch 0.02\n",
      "Epoch: [12][199/235]\tLoss   0.10\tAcc  96.94\tTime/batch 0.02\n",
      "epoch 12\n",
      "Accuracy of the network on the 10000 test images: 97.1 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 0.001\n",
      "Epoch: [13][ 99/235]\tLoss   0.10\tAcc  96.88\tTime/batch 0.02\n",
      "Epoch: [13][199/235]\tLoss   0.10\tAcc  96.88\tTime/batch 0.02\n",
      "epoch 13\n",
      "Accuracy of the network on the 10000 test images: 96.6 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 0.001\n",
      "Epoch: [14][ 99/235]\tLoss   0.11\tAcc  96.66\tTime/batch 0.02\n",
      "Epoch: [14][199/235]\tLoss   0.11\tAcc  96.76\tTime/batch 0.02\n",
      "epoch 14\n",
      "Accuracy of the network on the 10000 test images: 95.7 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 0.001\n",
      "Epoch: [15][ 99/235]\tLoss   0.10\tAcc  96.78\tTime/batch 0.02\n",
      "Epoch: [15][199/235]\tLoss   0.10\tAcc  96.93\tTime/batch 0.02\n",
      "epoch 15\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 0.001\n",
      "Epoch: [16][ 99/235]\tLoss   0.08\tAcc  97.33\tTime/batch 0.02\n",
      "Epoch: [16][199/235]\tLoss   0.08\tAcc  97.36\tTime/batch 0.02\n",
      "epoch 16\n",
      "Accuracy of the network on the 10000 test images: 97.0 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 0.001\n",
      "Epoch: [17][ 99/235]\tLoss   0.08\tAcc  97.29\tTime/batch 0.02\n",
      "Epoch: [17][199/235]\tLoss   0.09\tAcc  97.14\tTime/batch 0.02\n",
      "epoch 17\n",
      "Accuracy of the network on the 10000 test images: 96.9 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 0.001\n",
      "Epoch: [18][ 99/235]\tLoss   0.08\tAcc  97.44\tTime/batch 0.02\n",
      "Epoch: [18][199/235]\tLoss   0.09\tAcc  97.33\tTime/batch 0.02\n",
      "epoch 18\n",
      "Accuracy of the network on the 10000 test images: 96.9 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 0.001\n",
      "Epoch: [19][ 99/235]\tLoss   0.10\tAcc  96.94\tTime/batch 0.02\n",
      "Epoch: [19][199/235]\tLoss   0.09\tAcc  97.09\tTime/batch 0.02\n",
      "epoch 19\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 0.001\n",
      "Epoch: [20][ 99/235]\tLoss   0.08\tAcc  97.55\tTime/batch 0.02\n",
      "Epoch: [20][199/235]\tLoss   0.08\tAcc  97.39\tTime/batch 0.02\n",
      "epoch 20\n",
      "Accuracy of the network on the 10000 test images: 96.7 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 0.001\n",
      "Epoch: [21][ 99/235]\tLoss   0.08\tAcc  97.32\tTime/batch 0.02\n",
      "Epoch: [21][199/235]\tLoss   0.09\tAcc  97.33\tTime/batch 0.02\n",
      "epoch 21\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 0.001\n",
      "Epoch: [22][ 99/235]\tLoss   0.09\tAcc  97.22\tTime/batch 0.02\n",
      "Epoch: [22][199/235]\tLoss   0.09\tAcc  97.24\tTime/batch 0.02\n",
      "epoch 22\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 0.001\n",
      "Epoch: [23][ 99/235]\tLoss   0.09\tAcc  97.28\tTime/batch 0.02\n",
      "Epoch: [23][199/235]\tLoss   0.09\tAcc  97.29\tTime/batch 0.02\n",
      "epoch 23\n",
      "Accuracy of the network on the 10000 test images: 96.8 %\n",
      "The best test accuracy so far: 97.3\n",
      "current learning rate = 0.001\n",
      "Epoch: [24][ 99/235]\tLoss   0.08\tAcc  97.57\tTime/batch 0.02\n",
      "Epoch: [24][199/235]\tLoss   0.08\tAcc  97.54\tTime/batch 0.02\n",
      "epoch 24\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 0.001\n",
      "Epoch: [25][ 99/235]\tLoss   0.09\tAcc  97.23\tTime/batch 0.02\n",
      "Epoch: [25][199/235]\tLoss   0.08\tAcc  97.26\tTime/batch 0.02\n",
      "epoch 25\n",
      "Accuracy of the network on the 10000 test images: 97.1 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 0.001\n",
      "Epoch: [26][ 99/235]\tLoss   0.07\tAcc  97.66\tTime/batch 0.02\n",
      "Epoch: [26][199/235]\tLoss   0.07\tAcc  97.63\tTime/batch 0.02\n",
      "epoch 26\n",
      "Accuracy of the network on the 10000 test images: 97.1 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 0.001\n",
      "Epoch: [27][ 99/235]\tLoss   0.08\tAcc  97.41\tTime/batch 0.02\n",
      "Epoch: [27][199/235]\tLoss   0.08\tAcc  97.43\tTime/batch 0.02\n",
      "epoch 27\n",
      "Accuracy of the network on the 10000 test images: 95.5 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 0.001\n",
      "Epoch: [28][ 99/235]\tLoss   0.10\tAcc  96.84\tTime/batch 0.02\n",
      "Epoch: [28][199/235]\tLoss   0.10\tAcc  96.95\tTime/batch 0.02\n",
      "epoch 28\n",
      "Accuracy of the network on the 10000 test images: 97.0 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 0.001\n",
      "Epoch: [29][ 99/235]\tLoss   0.08\tAcc  97.35\tTime/batch 0.02\n",
      "Epoch: [29][199/235]\tLoss   0.08\tAcc  97.39\tTime/batch 0.02\n",
      "epoch 29\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 0.001\n",
      "Epoch: [30][ 99/235]\tLoss   0.08\tAcc  97.31\tTime/batch 0.02\n",
      "Epoch: [30][199/235]\tLoss   0.09\tAcc  97.31\tTime/batch 0.02\n",
      "epoch 30\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 0.001\n",
      "Epoch: [31][ 99/235]\tLoss   0.09\tAcc  97.24\tTime/batch 0.02\n",
      "Epoch: [31][199/235]\tLoss   0.09\tAcc  97.21\tTime/batch 0.02\n",
      "epoch 31\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 0.001\n",
      "Epoch: [32][ 99/235]\tLoss   0.09\tAcc  97.28\tTime/batch 0.02\n",
      "Epoch: [32][199/235]\tLoss   0.08\tAcc  97.31\tTime/batch 0.02\n",
      "epoch 32\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.4\n",
      "current learning rate = 0.001\n",
      "Epoch: [33][ 99/235]\tLoss   0.08\tAcc  97.55\tTime/batch 0.02\n",
      "Epoch: [33][199/235]\tLoss   0.08\tAcc  97.36\tTime/batch 0.02\n",
      "epoch 33\n",
      "Accuracy of the network on the 10000 test images: 97.5 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [34][ 99/235]\tLoss   0.09\tAcc  97.39\tTime/batch 0.02\n",
      "Epoch: [34][199/235]\tLoss   0.09\tAcc  97.23\tTime/batch 0.02\n",
      "epoch 34\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [35][ 99/235]\tLoss   0.08\tAcc  97.46\tTime/batch 0.02\n",
      "Epoch: [35][199/235]\tLoss   0.09\tAcc  97.27\tTime/batch 0.02\n",
      "epoch 35\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [36][ 99/235]\tLoss   0.08\tAcc  97.45\tTime/batch 0.02\n",
      "Epoch: [36][199/235]\tLoss   0.08\tAcc  97.46\tTime/batch 0.02\n",
      "epoch 36\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [37][ 99/235]\tLoss   0.08\tAcc  97.59\tTime/batch 0.02\n",
      "Epoch: [37][199/235]\tLoss   0.08\tAcc  97.55\tTime/batch 0.02\n",
      "epoch 37\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [38][ 99/235]\tLoss   0.07\tAcc  97.68\tTime/batch 0.02\n",
      "Epoch: [38][199/235]\tLoss   0.08\tAcc  97.49\tTime/batch 0.02\n",
      "epoch 38\n",
      "Accuracy of the network on the 10000 test images: 97.1 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [39][ 99/235]\tLoss   0.08\tAcc  97.57\tTime/batch 0.02\n",
      "Epoch: [39][199/235]\tLoss   0.08\tAcc  97.55\tTime/batch 0.02\n",
      "epoch 39\n",
      "Accuracy of the network on the 10000 test images: 96.5 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [40][ 99/235]\tLoss   0.08\tAcc  97.36\tTime/batch 0.02\n",
      "Epoch: [40][199/235]\tLoss   0.08\tAcc  97.41\tTime/batch 0.02\n",
      "epoch 40\n",
      "Accuracy of the network on the 10000 test images: 97.0 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [41][ 99/235]\tLoss   0.07\tAcc  97.74\tTime/batch 0.02\n",
      "Epoch: [41][199/235]\tLoss   0.08\tAcc  97.60\tTime/batch 0.02\n",
      "epoch 41\n",
      "Accuracy of the network on the 10000 test images: 97.0 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [42][ 99/235]\tLoss   0.08\tAcc  97.58\tTime/batch 0.02\n",
      "Epoch: [42][199/235]\tLoss   0.08\tAcc  97.48\tTime/batch 0.02\n",
      "epoch 42\n",
      "Accuracy of the network on the 10000 test images: 96.7 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [43][ 99/235]\tLoss   0.08\tAcc  97.33\tTime/batch 0.02\n",
      "Epoch: [43][199/235]\tLoss   0.08\tAcc  97.37\tTime/batch 0.02\n",
      "epoch 43\n",
      "Accuracy of the network on the 10000 test images: 97.1 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [44][ 99/235]\tLoss   0.07\tAcc  97.69\tTime/batch 0.02\n",
      "Epoch: [44][199/235]\tLoss   0.07\tAcc  97.77\tTime/batch 0.02\n",
      "epoch 44\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [45][ 99/235]\tLoss   0.07\tAcc  97.88\tTime/batch 0.02\n",
      "Epoch: [45][199/235]\tLoss   0.07\tAcc  97.88\tTime/batch 0.02\n",
      "epoch 45\n",
      "Accuracy of the network on the 10000 test images: 97.5 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [46][ 99/235]\tLoss   0.07\tAcc  97.66\tTime/batch 0.02\n",
      "Epoch: [46][199/235]\tLoss   0.07\tAcc  97.65\tTime/batch 0.02\n",
      "epoch 46\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [47][ 99/235]\tLoss   0.07\tAcc  97.89\tTime/batch 0.02\n",
      "Epoch: [47][199/235]\tLoss   0.07\tAcc  97.74\tTime/batch 0.02\n",
      "epoch 47\n",
      "Accuracy of the network on the 10000 test images: 97.5 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [48][ 99/235]\tLoss   0.07\tAcc  97.76\tTime/batch 0.02\n",
      "Epoch: [48][199/235]\tLoss   0.07\tAcc  97.78\tTime/batch 0.02\n",
      "epoch 48\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.5\n",
      "current learning rate = 0.001\n",
      "Epoch: [49][ 99/235]\tLoss   0.07\tAcc  97.75\tTime/batch 0.02\n",
      "Epoch: [49][199/235]\tLoss   0.07\tAcc  97.79\tTime/batch 0.02\n",
      "epoch 49\n",
      "Accuracy of the network on the 10000 test images: 97.6 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [50][ 99/235]\tLoss   0.07\tAcc  97.52\tTime/batch 0.02\n",
      "Epoch: [50][199/235]\tLoss   0.07\tAcc  97.58\tTime/batch 0.02\n",
      "epoch 50\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [51][ 99/235]\tLoss   0.07\tAcc  97.54\tTime/batch 0.02\n",
      "Epoch: [51][199/235]\tLoss   0.07\tAcc  97.65\tTime/batch 0.02\n",
      "epoch 51\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [52][ 99/235]\tLoss   0.07\tAcc  97.76\tTime/batch 0.02\n",
      "Epoch: [52][199/235]\tLoss   0.07\tAcc  97.75\tTime/batch 0.02\n",
      "epoch 52\n",
      "Accuracy of the network on the 10000 test images: 97.0 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [53][ 99/235]\tLoss   0.08\tAcc  97.46\tTime/batch 0.02\n",
      "Epoch: [53][199/235]\tLoss   0.07\tAcc  97.62\tTime/batch 0.02\n",
      "epoch 53\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [54][ 99/235]\tLoss   0.07\tAcc  97.73\tTime/batch 0.02\n",
      "Epoch: [54][199/235]\tLoss   0.07\tAcc  97.70\tTime/batch 0.02\n",
      "epoch 54\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [55][ 99/235]\tLoss   0.07\tAcc  97.80\tTime/batch 0.02\n",
      "Epoch: [55][199/235]\tLoss   0.07\tAcc  97.68\tTime/batch 0.02\n",
      "epoch 55\n",
      "Accuracy of the network on the 10000 test images: 97.6 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [56][ 99/235]\tLoss   0.07\tAcc  97.73\tTime/batch 0.02\n",
      "Epoch: [56][199/235]\tLoss   0.07\tAcc  97.70\tTime/batch 0.02\n",
      "epoch 56\n",
      "Accuracy of the network on the 10000 test images: 97.6 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [57][ 99/235]\tLoss   0.06\tAcc  97.94\tTime/batch 0.02\n",
      "Epoch: [57][199/235]\tLoss   0.07\tAcc  97.91\tTime/batch 0.02\n",
      "epoch 57\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [58][ 99/235]\tLoss   0.07\tAcc  97.64\tTime/batch 0.02\n",
      "Epoch: [58][199/235]\tLoss   0.07\tAcc  97.72\tTime/batch 0.02\n",
      "epoch 58\n",
      "Accuracy of the network on the 10000 test images: 97.6 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [59][ 99/235]\tLoss   0.08\tAcc  97.63\tTime/batch 0.02\n",
      "Epoch: [59][199/235]\tLoss   0.07\tAcc  97.80\tTime/batch 0.02\n",
      "epoch 59\n",
      "Accuracy of the network on the 10000 test images: 97.6 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [60][ 99/235]\tLoss   0.07\tAcc  97.73\tTime/batch 0.02\n",
      "Epoch: [60][199/235]\tLoss   0.07\tAcc  97.81\tTime/batch 0.02\n",
      "epoch 60\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [61][ 99/235]\tLoss   0.07\tAcc  97.91\tTime/batch 0.02\n",
      "Epoch: [61][199/235]\tLoss   0.07\tAcc  97.87\tTime/batch 0.02\n",
      "epoch 61\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [62][ 99/235]\tLoss   0.06\tAcc  97.93\tTime/batch 0.02\n",
      "Epoch: [62][199/235]\tLoss   0.08\tAcc  97.58\tTime/batch 0.02\n",
      "epoch 62\n",
      "Accuracy of the network on the 10000 test images: 97.0 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [63][ 99/235]\tLoss   0.08\tAcc  97.61\tTime/batch 0.02\n",
      "Epoch: [63][199/235]\tLoss   0.07\tAcc  97.65\tTime/batch 0.02\n",
      "epoch 63\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [64][ 99/235]\tLoss   0.08\tAcc  97.55\tTime/batch 0.02\n",
      "Epoch: [64][199/235]\tLoss   0.08\tAcc  97.32\tTime/batch 0.02\n",
      "epoch 64\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [65][ 99/235]\tLoss   0.08\tAcc  97.48\tTime/batch 0.02\n",
      "Epoch: [65][199/235]\tLoss   0.08\tAcc  97.46\tTime/batch 0.02\n",
      "epoch 65\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [66][ 99/235]\tLoss   0.07\tAcc  97.73\tTime/batch 0.02\n",
      "Epoch: [66][199/235]\tLoss   0.07\tAcc  97.66\tTime/batch 0.02\n",
      "epoch 66\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [67][ 99/235]\tLoss   0.07\tAcc  97.76\tTime/batch 0.02\n",
      "Epoch: [67][199/235]\tLoss   0.07\tAcc  97.73\tTime/batch 0.02\n",
      "epoch 67\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [68][ 99/235]\tLoss   0.07\tAcc  97.73\tTime/batch 0.02\n",
      "Epoch: [68][199/235]\tLoss   0.07\tAcc  97.77\tTime/batch 0.02\n",
      "epoch 68\n",
      "Accuracy of the network on the 10000 test images: 97.6 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [69][ 99/235]\tLoss   0.07\tAcc  97.74\tTime/batch 0.02\n",
      "Epoch: [69][199/235]\tLoss   0.07\tAcc  97.63\tTime/batch 0.02\n",
      "epoch 69\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [70][ 99/235]\tLoss   0.08\tAcc  97.38\tTime/batch 0.02\n",
      "Epoch: [70][199/235]\tLoss   0.08\tAcc  97.48\tTime/batch 0.02\n",
      "epoch 70\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [71][ 99/235]\tLoss   0.07\tAcc  97.71\tTime/batch 0.02\n",
      "Epoch: [71][199/235]\tLoss   0.07\tAcc  97.60\tTime/batch 0.02\n",
      "epoch 71\n",
      "Accuracy of the network on the 10000 test images: 97.5 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [72][ 99/235]\tLoss   0.07\tAcc  97.88\tTime/batch 0.02\n",
      "Epoch: [72][199/235]\tLoss   0.08\tAcc  97.58\tTime/batch 0.02\n",
      "epoch 72\n",
      "Accuracy of the network on the 10000 test images: 96.7 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [73][ 99/235]\tLoss   0.08\tAcc  97.44\tTime/batch 0.02\n",
      "Epoch: [73][199/235]\tLoss   0.08\tAcc  97.44\tTime/batch 0.02\n",
      "epoch 73\n",
      "Accuracy of the network on the 10000 test images: 97.5 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [74][ 99/235]\tLoss   0.08\tAcc  97.57\tTime/batch 0.02\n",
      "Epoch: [74][199/235]\tLoss   0.08\tAcc  97.52\tTime/batch 0.02\n",
      "epoch 74\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [75][ 99/235]\tLoss   0.07\tAcc  97.73\tTime/batch 0.02\n",
      "Epoch: [75][199/235]\tLoss   0.08\tAcc  97.54\tTime/batch 0.02\n",
      "epoch 75\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [76][ 99/235]\tLoss   0.09\tAcc  97.36\tTime/batch 0.02\n",
      "Epoch: [76][199/235]\tLoss   0.08\tAcc  97.38\tTime/batch 0.02\n",
      "epoch 76\n",
      "Accuracy of the network on the 10000 test images: 97.6 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [77][ 99/235]\tLoss   0.08\tAcc  97.45\tTime/batch 0.02\n",
      "Epoch: [77][199/235]\tLoss   0.07\tAcc  97.58\tTime/batch 0.02\n",
      "epoch 77\n",
      "Accuracy of the network on the 10000 test images: 96.8 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [78][ 99/235]\tLoss   0.07\tAcc  97.71\tTime/batch 0.02\n",
      "Epoch: [78][199/235]\tLoss   0.07\tAcc  97.84\tTime/batch 0.02\n",
      "epoch 78\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [79][ 99/235]\tLoss   0.07\tAcc  97.73\tTime/batch 0.02\n",
      "Epoch: [79][199/235]\tLoss   0.07\tAcc  97.71\tTime/batch 0.02\n",
      "epoch 79\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [80][ 99/235]\tLoss   0.07\tAcc  97.82\tTime/batch 0.02\n",
      "Epoch: [80][199/235]\tLoss   0.07\tAcc  97.63\tTime/batch 0.02\n",
      "epoch 80\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [81][ 99/235]\tLoss   0.07\tAcc  97.86\tTime/batch 0.02\n",
      "Epoch: [81][199/235]\tLoss   0.07\tAcc  97.72\tTime/batch 0.02\n",
      "epoch 81\n",
      "Accuracy of the network on the 10000 test images: 97.6 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [82][ 99/235]\tLoss   0.08\tAcc  97.64\tTime/batch 0.02\n",
      "Epoch: [82][199/235]\tLoss   0.08\tAcc  97.59\tTime/batch 0.02\n",
      "epoch 82\n",
      "Accuracy of the network on the 10000 test images: 97.5 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [83][ 99/235]\tLoss   0.08\tAcc  97.47\tTime/batch 0.02\n",
      "Epoch: [83][199/235]\tLoss   0.08\tAcc  97.45\tTime/batch 0.02\n",
      "epoch 83\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [84][ 99/235]\tLoss   0.07\tAcc  97.63\tTime/batch 0.02\n",
      "Epoch: [84][199/235]\tLoss   0.07\tAcc  97.81\tTime/batch 0.02\n",
      "epoch 84\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.6\n",
      "current learning rate = 0.001\n",
      "Epoch: [85][ 99/235]\tLoss   0.07\tAcc  97.70\tTime/batch 0.02\n",
      "Epoch: [85][199/235]\tLoss   0.07\tAcc  97.70\tTime/batch 0.02\n",
      "epoch 85\n",
      "Accuracy of the network on the 10000 test images: 97.7 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [86][ 99/235]\tLoss   0.07\tAcc  97.72\tTime/batch 0.02\n",
      "Epoch: [86][199/235]\tLoss   0.07\tAcc  97.72\tTime/batch 0.02\n",
      "epoch 86\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [87][ 99/235]\tLoss   0.07\tAcc  97.75\tTime/batch 0.02\n",
      "Epoch: [87][199/235]\tLoss   0.07\tAcc  97.73\tTime/batch 0.02\n",
      "epoch 87\n",
      "Accuracy of the network on the 10000 test images: 97.5 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [88][ 99/235]\tLoss   0.07\tAcc  97.70\tTime/batch 0.02\n",
      "Epoch: [88][199/235]\tLoss   0.07\tAcc  97.72\tTime/batch 0.02\n",
      "epoch 88\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [89][ 99/235]\tLoss   0.07\tAcc  97.73\tTime/batch 0.02\n",
      "Epoch: [89][199/235]\tLoss   0.07\tAcc  97.67\tTime/batch 0.02\n",
      "epoch 89\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [90][ 99/235]\tLoss   0.08\tAcc  97.45\tTime/batch 0.02\n",
      "Epoch: [90][199/235]\tLoss   0.07\tAcc  97.64\tTime/batch 0.02\n",
      "epoch 90\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [91][ 99/235]\tLoss   0.07\tAcc  97.69\tTime/batch 0.02\n",
      "Epoch: [91][199/235]\tLoss   0.07\tAcc  97.74\tTime/batch 0.02\n",
      "epoch 91\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [92][ 99/235]\tLoss   0.07\tAcc  97.68\tTime/batch 0.02\n",
      "Epoch: [92][199/235]\tLoss   0.07\tAcc  97.80\tTime/batch 0.02\n",
      "epoch 92\n",
      "Accuracy of the network on the 10000 test images: 97.5 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [93][ 99/235]\tLoss   0.07\tAcc  97.94\tTime/batch 0.02\n",
      "Epoch: [93][199/235]\tLoss   0.06\tAcc  97.94\tTime/batch 0.02\n",
      "epoch 93\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [94][ 99/235]\tLoss   0.07\tAcc  97.84\tTime/batch 0.02\n",
      "Epoch: [94][199/235]\tLoss   0.07\tAcc  97.87\tTime/batch 0.02\n",
      "epoch 94\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [95][ 99/235]\tLoss   0.07\tAcc  97.59\tTime/batch 0.02\n",
      "Epoch: [95][199/235]\tLoss   0.07\tAcc  97.67\tTime/batch 0.02\n",
      "epoch 95\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [96][ 99/235]\tLoss   0.07\tAcc  97.88\tTime/batch 0.02\n",
      "Epoch: [96][199/235]\tLoss   0.07\tAcc  97.82\tTime/batch 0.02\n",
      "epoch 96\n",
      "Accuracy of the network on the 10000 test images: 97.6 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [97][ 99/235]\tLoss   0.07\tAcc  97.87\tTime/batch 0.02\n",
      "Epoch: [97][199/235]\tLoss   0.07\tAcc  97.91\tTime/batch 0.02\n",
      "epoch 97\n",
      "Accuracy of the network on the 10000 test images: 97.5 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [98][ 99/235]\tLoss   0.06\tAcc  98.07\tTime/batch 0.02\n",
      "Epoch: [98][199/235]\tLoss   0.06\tAcc  98.02\tTime/batch 0.02\n",
      "epoch 98\n",
      "Accuracy of the network on the 10000 test images: 97.3 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [99][ 99/235]\tLoss   0.06\tAcc  98.07\tTime/batch 0.02\n",
      "Epoch: [99][199/235]\tLoss   0.06\tAcc  98.05\tTime/batch 0.02\n",
      "epoch 99\n",
      "Accuracy of the network on the 10000 test images: 97.7 %\n",
      "The best test accuracy so far: 97.7\n",
      "current learning rate = 0.001\n",
      "Epoch: [100][ 99/235]\tLoss   0.06\tAcc  98.10\tTime/batch 0.02\n",
      "Epoch: [100][199/235]\tLoss   0.06\tAcc  97.95\tTime/batch 0.02\n",
      "epoch 100\n",
      "Accuracy of the network on the 10000 test images: 97.5 %\n",
      "The best test accuracy so far: 97.7\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = binary_VGG_small(num_classes=10).to(device)\n",
    "\n",
    "criterion = (nn.CrossEntropyLoss().cuda() \n",
    "            if torch.cuda.is_available() else nn.CrossEntropyLoss())\n",
    "\n",
    "best_acc = 0.0\n",
    "best_model = copy.deepcopy(net.state_dict())\n",
    "start_epoch =0\n",
    "num_epoch = 100\n",
    "initial_lr = 1e-3\n",
    "weight_decay = 1e-5\n",
    "last_epoch = -1\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),\n",
    "                          lr = initial_lr,\n",
    "                          weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "lr_decay_milestones = [100, 150, 200]\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "                            optimizer,\n",
    "                            milestones=lr_decay_milestones,\n",
    "                            gamma=0.1,\n",
    "                            last_epoch=last_epoch)\n",
    "\n",
    "\n",
    "def sparsity(testloader, net, device):\n",
    "    num_out, num_high = [], []\n",
    "\n",
    "    def _report_sparsity(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if isinstance(m, q.PGBinaryConv2d):\n",
    "            num_out.append(m.num_out)\n",
    "            num_high.append(m.num_high)\n",
    "\n",
    "    net.eval()\n",
    "    # initialize cnt_out, cnt_high\n",
    "    net.apply(_report_sparsity)\n",
    "    cnt_out = np.zeros(len(num_out))\n",
    "    cnt_high = np.zeros(len(num_high))\n",
    "    num_out, num_high = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            \"\"\" calculate statistics per PG layer \"\"\"\n",
    "            net.apply(_report_sparsity)\n",
    "            cnt_out += np.array(num_out)\n",
    "            cnt_high += np.array(num_high)\n",
    "            num_out = []\n",
    "            num_high = []\n",
    "    print('Sparsity of the update phase: %.1f %%' %\n",
    "          (100.0-np.sum(cnt_high)*1.0/np.sum(cnt_out)*100.0))\n",
    "\n",
    "\n",
    "def test_accu(testloader, net, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # switch the model to the evaluation mode\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print('Accuracy of the network on the 10000 test images: %.1f %%' % accuracy)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch,num_epoch): # loop over the dataset multiple times\n",
    "\n",
    "    # set printing functions\n",
    "    batch_time = util.AverageMeter('Time/batch', ':.2f')\n",
    "    losses = util.AverageMeter('Loss', ':6.2f')\n",
    "    top1 = util.AverageMeter('Acc', ':6.2f')\n",
    "    progress = util.ProgressMeter(\n",
    "                    len(trainloader),\n",
    "                    [losses, top1, batch_time],\n",
    "                    prefix=\"Epoch: [{}]\".format(epoch+1)\n",
    "                    )\n",
    "\n",
    "    # switch the model to the training mode\n",
    "    net.train()\n",
    "\n",
    "    print('current learning rate = {}'.format(optimizer.param_groups[0]['lr']))\n",
    "    \n",
    "    # each epoch\n",
    "    end = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # for name, param in net.named_parameters():\n",
    "        #     if 'threshold' in name:\n",
    "        #         loss += (0.00001 * 0.5 *\n",
    "        #                     torch.norm(param-args.gtarget) *\n",
    "        #                     torch.norm(param-args.gtarget))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        _, batch_predicted = torch.max(outputs.data, 1)\n",
    "        batch_accu = 100.0 * (batch_predicted == labels).sum().item() / labels.size(0)\n",
    "        losses.update(loss.item(), labels.size(0))\n",
    "        top1.update(batch_accu, labels.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 99:    \n",
    "            # print statistics every 100 mini-batches each epoch\n",
    "            progress.display(i) # i = batch id in the epoch\n",
    "\n",
    "    # update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # print test accuracy every few epochs\n",
    "    if epoch % 1 == 0:\n",
    "        print('epoch {}'.format(epoch+1))\n",
    "        epoch_acc = test_accu(testloader, net, device)\n",
    "        # sparsity(testloader, net, device)\n",
    "        if epoch_acc >= best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model = copy.deepcopy(net.state_dict())\n",
    "        print(\"The best test accuracy so far: {:.1f}\".format(best_acc))\n",
    "\n",
    "        # save the model if required\n",
    "        # if args.save:\n",
    "        #     print(\"Saving the trained model and states.\")\n",
    "        #     this_file_path = os.path.dirname(os.path.abspath(__file__))\n",
    "        #     save_folder = os.path.join(this_file_path, 'save_CIFAR10_model')\n",
    "        #     util.save_models(best_model, save_folder,\n",
    "        #             suffix=_ARCH+'-finetune' if args.finetune else _ARCH)\n",
    "        #     \"\"\"\n",
    "        #     states = {'epoch':epoch+1, \n",
    "        #                 'optimizer':optimizer.state_dict(), \n",
    "        #                 'scheduler':scheduler.state_dict()}\n",
    "        #     util.save_states(states, save_folder, suffix=_ARCH)\n",
    "        #     \"\"\"\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0b98644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight tensor([[[[-3.6147e-02, -5.6324e-02,  4.2087e-02],\n",
      "          [-1.5825e-02, -6.6599e-02, -3.0793e-02],\n",
      "          [-4.9579e-02, -4.5765e-02,  5.4359e-02]],\n",
      "\n",
      "         [[-5.0926e-03, -2.2623e-02,  9.0508e-02],\n",
      "          [-4.5542e-02,  1.8164e-02,  2.4676e-02],\n",
      "          [-1.0542e-01,  1.2314e-02, -2.5641e-02]],\n",
      "\n",
      "         [[-4.5086e-02,  3.1706e-02,  2.6759e-02],\n",
      "          [-1.1363e-02,  9.8884e-03,  1.0409e-02],\n",
      "          [-8.4782e-02, -7.2667e-02,  5.7489e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.8576e-03,  2.1478e-02,  1.3151e-01],\n",
      "          [-3.1922e-02, -9.5062e-03,  1.4333e-01],\n",
      "          [ 4.7473e-02, -1.0527e-02,  1.3833e-01]],\n",
      "\n",
      "         [[ 7.3301e-03,  1.2018e-01,  9.2022e-02],\n",
      "          [ 2.3729e-02,  6.8309e-02,  7.3373e-02],\n",
      "          [ 3.0666e-02,  4.2969e-02,  9.8334e-02]],\n",
      "\n",
      "         [[ 6.8416e-02,  1.3557e-01,  1.6545e-01],\n",
      "          [-3.6064e-04, -9.1317e-03,  1.4463e-01],\n",
      "          [ 8.5003e-02, -1.9483e-02,  1.1767e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5781e-01, -7.4925e-02, -6.6176e-02],\n",
      "          [-5.2077e-02, -6.1533e-03, -5.9016e-02],\n",
      "          [ 6.1852e-02,  6.4237e-02,  3.2187e-02]],\n",
      "\n",
      "         [[-7.8294e-02, -3.8648e-02, -6.7644e-02],\n",
      "          [-1.0294e-01, -4.9167e-03, -1.1057e-01],\n",
      "          [ 4.0397e-02,  2.3048e-02, -1.4353e-02]],\n",
      "\n",
      "         [[-1.0802e-01, -7.6866e-02, -6.4959e-02],\n",
      "          [-9.4019e-02,  4.0409e-02, -8.5427e-02],\n",
      "          [ 3.3225e-02, -4.0699e-02, -5.2162e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9909e-02, -7.5424e-02,  1.7522e-02],\n",
      "          [-4.5777e-02, -8.4807e-02, -3.8365e-04],\n",
      "          [ 4.6687e-02, -8.1662e-03, -1.2775e-02]],\n",
      "\n",
      "         [[-8.2905e-02, -7.6631e-02,  8.4370e-03],\n",
      "          [ 1.2318e-02, -1.1554e-01,  6.3877e-04],\n",
      "          [ 5.5900e-02, -9.3147e-02,  3.7969e-02]],\n",
      "\n",
      "         [[-4.3603e-02, -1.5642e-01, -3.9572e-02],\n",
      "          [-3.5118e-02, -1.1248e-01, -1.7857e-02],\n",
      "          [-1.3004e-04,  7.9626e-03,  5.0288e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1507e-02, -8.1153e-03,  8.0889e-02],\n",
      "          [-6.0804e-02,  3.8935e-03, -2.3602e-02],\n",
      "          [-1.1344e-01, -4.2456e-02, -5.0834e-02]],\n",
      "\n",
      "         [[ 2.6314e-02,  1.0782e-01,  8.4937e-02],\n",
      "          [-7.0569e-02,  6.2606e-02,  4.5230e-02],\n",
      "          [-9.1216e-02, -5.1372e-02, -4.8609e-02]],\n",
      "\n",
      "         [[ 2.5982e-02,  1.7453e-02,  5.9036e-02],\n",
      "          [-8.0613e-02, -9.1946e-04, -2.7760e-02],\n",
      "          [-8.6427e-02, -5.1379e-02, -1.8512e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.2592e-03,  6.4916e-02,  7.5543e-02],\n",
      "          [-1.3331e-01,  1.1533e-02,  3.1830e-02],\n",
      "          [-7.4860e-02,  4.0138e-03, -5.3527e-02]],\n",
      "\n",
      "         [[-5.2238e-02,  1.9456e-02,  8.0619e-02],\n",
      "          [-1.2517e-01, -2.5535e-03,  1.0771e-01],\n",
      "          [ 3.3234e-02, -2.8253e-02,  3.8573e-02]],\n",
      "\n",
      "         [[-1.2997e-02, -3.7529e-02,  1.1447e-02],\n",
      "          [-8.4138e-02, -2.4250e-02,  7.7427e-02],\n",
      "          [-2.4944e-02,  6.9780e-02, -5.5435e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.1474e-02,  6.8132e-02,  1.9838e-02],\n",
      "          [ 1.6515e-02, -2.4971e-02, -4.9844e-02],\n",
      "          [-7.1438e-02,  2.3308e-02, -4.5706e-02]],\n",
      "\n",
      "         [[ 3.2845e-02, -1.8516e-02, -2.9146e-02],\n",
      "          [-1.1221e-01, -1.1999e-01, -1.5120e-02],\n",
      "          [-6.9351e-02, -7.1038e-02, -1.0077e-01]],\n",
      "\n",
      "         [[ 1.9515e-02,  5.6169e-02,  2.2570e-02],\n",
      "          [-7.9725e-02, -7.3505e-02, -3.6254e-02],\n",
      "          [-9.5214e-02, -1.0684e-01,  2.0840e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3506e-02, -4.1756e-02, -7.3419e-02],\n",
      "          [-4.5936e-02,  1.9400e-02, -2.5104e-02],\n",
      "          [-5.5557e-02, -1.1188e-01, -5.1818e-02]],\n",
      "\n",
      "         [[ 3.8262e-02, -1.8359e-02, -4.4938e-02],\n",
      "          [-7.3882e-02, -1.4820e-02,  4.8370e-02],\n",
      "          [-3.1210e-02, -8.3891e-02, -6.2613e-02]],\n",
      "\n",
      "         [[-9.1121e-03, -5.4016e-02, -9.7130e-02],\n",
      "          [ 2.1426e-02,  8.5015e-03, -1.5606e-02],\n",
      "          [-9.8023e-02, -7.6987e-02, -7.9276e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0245e-02,  4.2995e-02,  9.5181e-02],\n",
      "          [ 1.3604e-01,  6.5718e-02,  5.5290e-02],\n",
      "          [ 7.4396e-02, -1.1782e-02, -7.8625e-02]],\n",
      "\n",
      "         [[ 2.4472e-02,  7.1892e-02, -1.8716e-03],\n",
      "          [ 7.7025e-02,  8.3905e-02,  4.2604e-02],\n",
      "          [-1.6293e-02,  6.1816e-02, -1.3684e-01]],\n",
      "\n",
      "         [[ 7.5417e-02,  6.7705e-02, -2.7486e-02],\n",
      "          [ 1.2735e-01,  4.5295e-02, -3.0988e-02],\n",
      "          [ 1.6188e-02, -3.1712e-02, -8.4372e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8838e-02,  6.4072e-02,  5.5377e-02],\n",
      "          [-2.6207e-02,  3.9224e-02, -1.7052e-01],\n",
      "          [-2.5920e-02, -1.7005e-02, -6.5842e-02]],\n",
      "\n",
      "         [[-1.0165e-01,  4.1308e-02, -3.3381e-02],\n",
      "          [ 2.7236e-03, -2.3621e-02, -6.0167e-02],\n",
      "          [-6.4718e-02, -3.1101e-02, -6.0715e-02]],\n",
      "\n",
      "         [[-7.3091e-02,  6.7472e-02, -1.8383e-02],\n",
      "          [ 7.4162e-03, -5.5314e-02, -1.5723e-01],\n",
      "          [-4.7109e-02, -5.0414e-02,  2.7029e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0944e-02, -3.0265e-02, -7.4201e-02],\n",
      "          [ 3.4766e-02, -3.8950e-02, -8.3364e-02],\n",
      "          [-3.4350e-02,  5.0836e-02, -1.3075e-02]],\n",
      "\n",
      "         [[ 8.1799e-02, -1.0188e-01, -3.9084e-02],\n",
      "          [ 2.1422e-02, -1.4855e-01, -1.0514e-01],\n",
      "          [ 4.9333e-02, -4.2432e-02,  8.3042e-02]],\n",
      "\n",
      "         [[ 5.4183e-02, -8.0093e-02, -6.0526e-02],\n",
      "          [ 2.0305e-02, -1.4307e-01, -7.0468e-02],\n",
      "          [ 3.1525e-02,  6.1017e-02, -4.3227e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1137e-01, -3.7065e-02, -1.1380e-01],\n",
      "          [-5.4994e-02, -4.2608e-02, -4.7944e-02],\n",
      "          [ 4.3530e-02,  5.8153e-02,  2.5175e-02]],\n",
      "\n",
      "         [[-9.3496e-02, -6.4323e-02, -1.1351e-01],\n",
      "          [-5.5874e-02, -5.3724e-02, -2.2021e-02],\n",
      "          [ 6.6951e-03, -1.8805e-02,  3.4795e-02]],\n",
      "\n",
      "         [[-2.1280e-02, -3.2605e-02, -5.8190e-02],\n",
      "          [-1.9461e-02,  3.3564e-02,  1.4295e-02],\n",
      "          [ 1.6515e-02,  4.6165e-02,  1.3134e-02]]]], device='cuda:0')\n",
      "conv1.bias tensor([-0.1062,  0.0213,  0.0294,  0.0285, -0.0528,  0.0130,  0.0459, -0.1136,\n",
      "        -0.0676, -0.0016,  0.0498,  0.1149,  0.0997,  0.1320, -0.0042, -0.0297,\n",
      "         0.0437,  0.1036,  0.0092,  0.0002,  0.1162,  0.0303,  0.0105,  0.0947,\n",
      "        -0.0010, -0.0718,  0.0016,  0.0426, -0.0610,  0.0480, -0.0542, -0.0701,\n",
      "         0.1704, -0.1226,  0.1542,  0.0761, -0.0564,  0.0838, -0.0656, -0.1527,\n",
      "        -0.0654,  0.0791,  0.0499,  0.0992, -0.0096,  0.0410,  0.0496, -0.0911,\n",
      "        -0.0457, -0.0050, -0.0482,  0.0201,  0.0154, -0.0153,  0.0643, -0.1005,\n",
      "         0.0336, -0.0015, -0.0354, -0.0195,  0.0866, -0.0515,  0.0989,  0.0184],\n",
      "       device='cuda:0')\n",
      "conv2.weight tensor([[[[-8.1525e-02, -3.2971e-02, -2.2701e-02],\n",
      "          [ 3.4809e-02, -2.4334e-02, -6.4342e-02],\n",
      "          [ 3.2439e-02, -1.6536e-02,  7.9927e-02]],\n",
      "\n",
      "         [[ 5.8601e-03,  7.3888e-02,  1.0047e-01],\n",
      "          [ 5.7354e-02,  1.5916e-02,  1.4112e-01],\n",
      "          [ 5.4810e-02,  5.6961e-02,  1.4902e-01]],\n",
      "\n",
      "         [[-1.3260e-02, -6.4621e-02, -2.1518e-02],\n",
      "          [-3.9188e-02, -8.8048e-02, -1.5074e-01],\n",
      "          [-3.0245e-02, -2.3356e-02,  3.1393e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7347e-02,  1.1694e-03,  8.8253e-02],\n",
      "          [ 5.2984e-02,  3.9828e-02, -9.6085e-03],\n",
      "          [ 2.5486e-02,  3.3108e-02, -3.2058e-02]],\n",
      "\n",
      "         [[ 5.9424e-02,  9.8023e-02, -3.3805e-02],\n",
      "          [-8.3512e-03,  2.3770e-02, -6.6052e-02],\n",
      "          [ 4.9083e-02, -7.1760e-02, -1.3512e-02]],\n",
      "\n",
      "         [[ 1.0115e-02,  1.4023e-01,  7.7101e-02],\n",
      "          [ 1.4035e-02,  9.2841e-02,  1.6231e-01],\n",
      "          [ 3.6994e-02,  2.1368e-02, -5.5045e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3437e-02, -4.4684e-02,  1.2007e-02],\n",
      "          [-3.3279e-03, -4.2352e-02, -7.9793e-03],\n",
      "          [ 1.0731e-01,  8.9233e-02,  3.0381e-02]],\n",
      "\n",
      "         [[-1.1181e-02,  6.0833e-02,  8.9140e-02],\n",
      "          [ 6.4528e-02,  4.9062e-02,  3.1010e-03],\n",
      "          [-6.5637e-02, -4.4777e-02, -4.9515e-02]],\n",
      "\n",
      "         [[ 2.7937e-02, -5.1430e-02, -9.8988e-02],\n",
      "          [-3.6770e-02, -3.3685e-02, -9.9611e-02],\n",
      "          [ 1.2949e-02,  4.4222e-02, -3.2333e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3253e-03, -8.7215e-02,  2.2971e-02],\n",
      "          [-1.0460e-01, -1.6848e-01, -7.3626e-02],\n",
      "          [-1.0407e-01, -1.3514e-01, -2.0041e-02]],\n",
      "\n",
      "         [[-6.4203e-02, -1.2652e-02,  7.5176e-02],\n",
      "          [-4.8361e-02,  8.9299e-03,  2.1664e-02],\n",
      "          [-5.7657e-02, -3.6392e-02, -5.3991e-02]],\n",
      "\n",
      "         [[-4.4005e-02,  4.8747e-03,  2.9555e-02],\n",
      "          [-1.8051e-02, -2.4576e-02, -2.7319e-02],\n",
      "          [-1.7695e-01, -5.9865e-02, -3.3580e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.2543e-03,  1.2643e-02, -4.7921e-02],\n",
      "          [ 2.4153e-02,  1.5639e-02,  4.6358e-03],\n",
      "          [-1.3643e-02,  5.4949e-03,  2.9778e-02]],\n",
      "\n",
      "         [[ 4.1521e-02,  2.2091e-03, -8.1067e-02],\n",
      "          [ 2.4509e-02, -1.4998e-02,  5.8191e-02],\n",
      "          [ 4.6092e-02,  1.0777e-01,  9.3334e-02]],\n",
      "\n",
      "         [[ 3.5576e-03,  2.4330e-02, -4.6062e-03],\n",
      "          [-4.8550e-02, -2.0326e-02, -2.9647e-02],\n",
      "          [-7.6531e-02, -2.7845e-02, -5.8362e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1192e-02,  3.6695e-02,  2.2059e-02],\n",
      "          [ 3.3145e-02,  8.6718e-02,  7.0520e-02],\n",
      "          [ 1.0644e-02,  1.1139e-01,  1.0601e-01]],\n",
      "\n",
      "         [[ 5.7258e-02,  4.0787e-02,  1.1552e-02],\n",
      "          [ 2.9855e-02,  3.8486e-02, -1.4574e-02],\n",
      "          [-5.8774e-02, -1.2745e-03,  7.9352e-03]],\n",
      "\n",
      "         [[ 2.5877e-02,  3.6340e-02,  7.8534e-02],\n",
      "          [ 8.5654e-02,  8.1085e-02, -1.2103e-02],\n",
      "          [-1.5514e-02,  1.3560e-01,  4.4418e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0078e-02,  2.5253e-02,  8.7059e-02],\n",
      "          [-5.2350e-02,  9.0553e-03,  4.4881e-02],\n",
      "          [-6.7584e-03, -3.3897e-02, -6.5737e-03]],\n",
      "\n",
      "         [[-2.9416e-02,  1.2380e-02, -4.8596e-02],\n",
      "          [-3.3646e-02,  1.1127e-01,  3.9349e-02],\n",
      "          [-4.0546e-02,  6.9679e-02,  5.5555e-04]],\n",
      "\n",
      "         [[ 1.0027e-02, -6.4191e-02, -7.3874e-02],\n",
      "          [-3.4129e-02, -1.2663e-01, -2.0594e-03],\n",
      "          [-8.7006e-02, -7.7364e-02, -1.2562e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4415e-02,  2.2452e-02,  8.4306e-02],\n",
      "          [ 1.5602e-02, -3.2941e-02,  7.2456e-02],\n",
      "          [ 2.8743e-03, -1.4272e-02,  1.1038e-01]],\n",
      "\n",
      "         [[ 1.7264e-02,  3.2143e-02, -1.5263e-02],\n",
      "          [ 7.6539e-03,  4.1389e-02,  7.0431e-02],\n",
      "          [-3.8554e-02, -1.4420e-02,  7.8363e-02]],\n",
      "\n",
      "         [[ 4.0091e-02,  5.4353e-02,  9.7423e-02],\n",
      "          [-2.2536e-02,  1.0824e-01,  7.2245e-02],\n",
      "          [-6.6602e-03,  4.6168e-02,  6.2325e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4923e-02,  1.5162e-02, -1.3758e-02],\n",
      "          [ 8.8283e-02,  4.8608e-02, -6.1963e-02],\n",
      "          [ 7.2431e-02,  1.3363e-02, -7.7147e-02]],\n",
      "\n",
      "         [[-2.9135e-03,  1.3067e-01,  2.3136e-02],\n",
      "          [ 2.2253e-02, -4.1413e-02,  2.9423e-02],\n",
      "          [-6.6403e-02, -1.4948e-01, -7.5063e-02]],\n",
      "\n",
      "         [[-3.2043e-02, -1.6585e-02, -3.8723e-02],\n",
      "          [ 9.5014e-02,  8.9666e-02, -7.8015e-02],\n",
      "          [ 8.1967e-02,  4.4997e-02,  1.7603e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7814e-02, -3.8380e-03, -2.6498e-02],\n",
      "          [-1.7076e-02, -2.4241e-02, -4.2867e-02],\n",
      "          [-4.3564e-02, -2.4562e-02, -1.5163e-02]],\n",
      "\n",
      "         [[-3.1644e-02, -1.9478e-02,  3.8803e-03],\n",
      "          [-5.9817e-02, -3.8772e-02,  3.5614e-02],\n",
      "          [-5.7217e-02,  5.7703e-03,  7.7714e-02]],\n",
      "\n",
      "         [[-3.2516e-02,  2.3160e-02,  3.2058e-02],\n",
      "          [-5.3024e-02, -5.7827e-02, -3.3705e-03],\n",
      "          [-8.3296e-02, -6.8652e-02, -3.3998e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8974e-02,  4.5511e-02, -7.4066e-02],\n",
      "          [ 3.7520e-02,  1.7089e-03, -4.1121e-02],\n",
      "          [-1.1106e-04, -2.8336e-02,  4.1530e-03]],\n",
      "\n",
      "         [[-4.8041e-02, -1.1733e-01, -8.7419e-02],\n",
      "          [-5.5999e-02, -8.2423e-02, -1.4276e-03],\n",
      "          [-2.8319e-02, -5.0555e-02,  4.0272e-02]],\n",
      "\n",
      "         [[ 9.4416e-03,  7.3201e-02,  1.5064e-02],\n",
      "          [ 6.4254e-02,  3.1074e-02,  3.0390e-02],\n",
      "          [ 2.0867e-02,  9.0491e-02,  5.7135e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0719e-01,  6.0443e-03,  5.2786e-03],\n",
      "          [ 1.0671e-01,  9.3602e-02,  5.9996e-03],\n",
      "          [ 8.1305e-02,  1.7186e-01,  4.5693e-02]],\n",
      "\n",
      "         [[-2.1076e-03,  1.5032e-02,  1.9341e-02],\n",
      "          [ 1.2156e-02, -3.1829e-02,  8.4962e-03],\n",
      "          [ 5.2177e-02,  1.4462e-03, -3.6208e-03]],\n",
      "\n",
      "         [[ 9.0342e-03,  2.0429e-02, -3.9468e-02],\n",
      "          [ 4.2643e-02, -5.1049e-02, -4.4169e-02],\n",
      "          [ 5.0270e-02, -4.4130e-04, -4.6054e-03]]]], device='cuda:0')\n",
      "conv2.bias tensor([-0.0578, -0.0910, -0.0955,  0.1248,  0.0027, -0.0327,  0.0057, -0.0810,\n",
      "         0.0926,  0.0320, -0.1132,  0.0007, -0.0565,  0.0310, -0.0168, -0.0457,\n",
      "         0.0037,  0.1103,  0.0346,  0.0307, -0.0503, -0.0254,  0.0095, -0.0946,\n",
      "         0.0225, -0.0664,  0.0154,  0.0396,  0.0290,  0.0553,  0.0024,  0.0284,\n",
      "        -0.0194, -0.0503,  0.1694, -0.0188, -0.0206, -0.0748,  0.0293, -0.0036,\n",
      "        -0.0066,  0.0721,  0.0319, -0.0155, -0.0089,  0.0472, -0.0974, -0.0652,\n",
      "         0.0778,  0.0167,  0.0935, -0.0848, -0.0501,  0.0675, -0.0154, -0.0539,\n",
      "         0.0954, -0.0184, -0.0262, -0.0004,  0.0677,  0.0166,  0.0357,  0.0426],\n",
      "       device='cuda:0')\n",
      "conv3.weight tensor([[[[ 0.1609,  0.0389,  0.0907],\n",
      "          [ 0.0577,  0.0822,  0.1194],\n",
      "          [ 0.0311,  0.0701,  0.0190]],\n",
      "\n",
      "         [[ 0.0212,  0.0255, -0.0202],\n",
      "          [ 0.0022,  0.0530,  0.0317],\n",
      "          [-0.0459, -0.0401, -0.0063]],\n",
      "\n",
      "         [[ 0.0579,  0.0335,  0.0968],\n",
      "          [ 0.1238,  0.0389, -0.0247],\n",
      "          [ 0.0045,  0.0556, -0.0615]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0322,  0.0289,  0.0483],\n",
      "          [ 0.0825,  0.0791,  0.0141],\n",
      "          [ 0.0248,  0.0921,  0.0691]],\n",
      "\n",
      "         [[-0.0372, -0.0865, -0.0715],\n",
      "          [ 0.0138, -0.0660, -0.0178],\n",
      "          [-0.0633,  0.0276,  0.0968]],\n",
      "\n",
      "         [[ 0.0432,  0.0306,  0.0301],\n",
      "          [ 0.0867,  0.0372, -0.0010],\n",
      "          [ 0.0905,  0.0464, -0.0051]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0438,  0.0748,  0.0426],\n",
      "          [ 0.1350,  0.0452, -0.0222],\n",
      "          [-0.0128, -0.1469, -0.0958]],\n",
      "\n",
      "         [[-0.0588,  0.0697, -0.0534],\n",
      "          [-0.0542,  0.0765,  0.0191],\n",
      "          [ 0.0084,  0.0822,  0.1096]],\n",
      "\n",
      "         [[-0.0160, -0.0192,  0.0604],\n",
      "          [ 0.0648, -0.0491,  0.0447],\n",
      "          [-0.0924, -0.0720, -0.0547]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0153,  0.0296,  0.0446],\n",
      "          [ 0.0117, -0.0347, -0.0987],\n",
      "          [-0.0394, -0.0466, -0.0401]],\n",
      "\n",
      "         [[-0.0597,  0.0479, -0.0619],\n",
      "          [-0.0062,  0.1116, -0.0303],\n",
      "          [ 0.0564,  0.2207,  0.0483]],\n",
      "\n",
      "         [[-0.0591, -0.0026, -0.0801],\n",
      "          [ 0.0460, -0.0699, -0.1202],\n",
      "          [-0.0420,  0.0223, -0.0697]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0180,  0.1316,  0.0473],\n",
      "          [ 0.0052,  0.0812,  0.0284],\n",
      "          [-0.0621,  0.0632,  0.0148]],\n",
      "\n",
      "         [[-0.0481, -0.0220,  0.0317],\n",
      "          [ 0.0984,  0.0358,  0.0379],\n",
      "          [ 0.0428, -0.0386, -0.1394]],\n",
      "\n",
      "         [[ 0.1048,  0.0501, -0.0234],\n",
      "          [-0.0394,  0.0097,  0.0789],\n",
      "          [-0.0733, -0.0158,  0.1049]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0224,  0.1218,  0.0473],\n",
      "          [-0.0290, -0.0453, -0.0190],\n",
      "          [-0.0207,  0.0776,  0.0380]],\n",
      "\n",
      "         [[ 0.0008,  0.0099,  0.0931],\n",
      "          [ 0.0198,  0.1382,  0.0649],\n",
      "          [ 0.0769,  0.0194, -0.0337]],\n",
      "\n",
      "         [[ 0.0765,  0.0044,  0.0107],\n",
      "          [ 0.0043,  0.1033,  0.0117],\n",
      "          [ 0.1160,  0.0375, -0.0891]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0456, -0.0191,  0.0028],\n",
      "          [-0.0431, -0.0357,  0.0316],\n",
      "          [ 0.0617, -0.0079,  0.0680]],\n",
      "\n",
      "         [[ 0.2045,  0.1587,  0.0577],\n",
      "          [ 0.0411, -0.0147, -0.0605],\n",
      "          [-0.0257, -0.1037,  0.0141]],\n",
      "\n",
      "         [[-0.1253, -0.1359, -0.0115],\n",
      "          [-0.1136, -0.0452, -0.0149],\n",
      "          [ 0.0007, -0.0132, -0.0170]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0710,  0.0393,  0.0894],\n",
      "          [-0.0315, -0.0142,  0.1329],\n",
      "          [-0.0126, -0.0100,  0.0617]],\n",
      "\n",
      "         [[ 0.1151,  0.1028,  0.1702],\n",
      "          [ 0.0570,  0.0813,  0.0284],\n",
      "          [ 0.0068, -0.1010, -0.1017]],\n",
      "\n",
      "         [[ 0.0201,  0.0878,  0.1021],\n",
      "          [ 0.0574,  0.0995, -0.0385],\n",
      "          [-0.0637,  0.0043, -0.0563]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0436, -0.0763, -0.0518],\n",
      "          [ 0.0483,  0.0587,  0.0345],\n",
      "          [-0.0513,  0.0791,  0.0367]],\n",
      "\n",
      "         [[-0.0532, -0.0115, -0.0795],\n",
      "          [-0.0814, -0.0023, -0.1145],\n",
      "          [ 0.0138,  0.0157, -0.0060]],\n",
      "\n",
      "         [[-0.0489, -0.0099, -0.0996],\n",
      "          [-0.0209,  0.0417,  0.0283],\n",
      "          [-0.0626, -0.0933, -0.0146]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0791,  0.0405,  0.0205],\n",
      "          [ 0.1252,  0.0772,  0.1033],\n",
      "          [ 0.0383, -0.0518,  0.0327]],\n",
      "\n",
      "         [[-0.0200, -0.0118, -0.0279],\n",
      "          [-0.1034, -0.0791, -0.0367],\n",
      "          [-0.0469, -0.0033, -0.0191]],\n",
      "\n",
      "         [[ 0.0610,  0.2501,  0.2062],\n",
      "          [-0.0897, -0.0044, -0.0225],\n",
      "          [-0.0167, -0.0831, -0.0506]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1674,  0.1054,  0.0591],\n",
      "          [ 0.1008,  0.0554,  0.0713],\n",
      "          [ 0.0409,  0.0464,  0.0666]],\n",
      "\n",
      "         [[-0.1075, -0.1167, -0.0037],\n",
      "          [-0.0809, -0.0514, -0.0189],\n",
      "          [-0.0025, -0.0589,  0.0026]],\n",
      "\n",
      "         [[ 0.0853,  0.1106,  0.0566],\n",
      "          [ 0.1203,  0.1015, -0.0053],\n",
      "          [ 0.0202, -0.0018, -0.0326]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1344,  0.0677,  0.0040],\n",
      "          [ 0.0573,  0.0539,  0.0573],\n",
      "          [-0.0405, -0.0474,  0.0132]],\n",
      "\n",
      "         [[-0.1005, -0.0660, -0.0028],\n",
      "          [-0.0411,  0.0128,  0.0201],\n",
      "          [-0.0089,  0.0276,  0.0811]],\n",
      "\n",
      "         [[ 0.0094,  0.0886,  0.0071],\n",
      "          [-0.0476,  0.0174,  0.1437],\n",
      "          [ 0.0366,  0.0020,  0.0546]]]], device='cuda:0')\n",
      "conv3.bias tensor([ 0.1090, -0.0143, -0.0028, -0.0138, -0.0643, -0.0480, -0.1139,  0.0071,\n",
      "         0.0048,  0.0241, -0.0597,  0.0563, -0.0677,  0.0434,  0.0070,  0.0339,\n",
      "        -0.0387,  0.0372, -0.0629, -0.0323,  0.1087, -0.0228,  0.0640,  0.0929,\n",
      "         0.0992, -0.1173, -0.0443,  0.1252, -0.0474, -0.0281, -0.1417, -0.0970,\n",
      "        -0.0366,  0.0246, -0.0465,  0.1352,  0.0410, -0.0265,  0.0236, -0.0058,\n",
      "         0.0060,  0.1199,  0.0067,  0.0305, -0.0581,  0.0304,  0.0697, -0.0255,\n",
      "         0.0447,  0.1128,  0.0516,  0.0501,  0.0089, -0.0230,  0.0141,  0.1067,\n",
      "        -0.0030, -0.0107, -0.0304, -0.0220, -0.0531,  0.0075, -0.0375,  0.0347,\n",
      "        -0.0905,  0.0647,  0.0536, -0.0226,  0.0015, -0.0290,  0.0844,  0.0002,\n",
      "        -0.0091,  0.0053, -0.0159,  0.0022,  0.0923, -0.0222, -0.0408, -0.0271,\n",
      "         0.1157,  0.0093, -0.0124,  0.0454,  0.0676, -0.0552,  0.0545, -0.0430,\n",
      "         0.0385, -0.0206, -0.0299, -0.0144,  0.0039,  0.0667,  0.0046,  0.0125,\n",
      "         0.1004, -0.0482,  0.0176,  0.0337, -0.0117, -0.0314,  0.0137, -0.0456,\n",
      "         0.0476, -0.0312,  0.0101, -0.1058,  0.0466,  0.0220, -0.0522,  0.0784,\n",
      "         0.0359, -0.0778,  0.0634, -0.1396, -0.0717,  0.0212,  0.0391, -0.0334,\n",
      "        -0.0105,  0.0213, -0.0362, -0.0032, -0.0662,  0.0192, -0.0151,  0.0702],\n",
      "       device='cuda:0')\n",
      "conv4.weight tensor([[[[ 0.0892,  0.0148,  0.0249],\n",
      "          [ 0.1377,  0.0027,  0.0888],\n",
      "          [ 0.0224,  0.0473,  0.0798]],\n",
      "\n",
      "         [[ 0.0496,  0.0877,  0.0491],\n",
      "          [ 0.0919,  0.0607,  0.0971],\n",
      "          [ 0.0180,  0.0622,  0.0676]],\n",
      "\n",
      "         [[-0.0683, -0.0060,  0.0209],\n",
      "          [ 0.0429,  0.0228,  0.0457],\n",
      "          [ 0.0183,  0.0262,  0.0897]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0014,  0.0205,  0.0719],\n",
      "          [-0.0329,  0.0342,  0.1354],\n",
      "          [-0.0097,  0.0530,  0.1050]],\n",
      "\n",
      "         [[-0.0502, -0.0096, -0.0064],\n",
      "          [-0.0993, -0.0141,  0.0107],\n",
      "          [-0.0547, -0.0238, -0.0096]],\n",
      "\n",
      "         [[ 0.1393,  0.1001,  0.0625],\n",
      "          [ 0.1323,  0.0275,  0.0081],\n",
      "          [ 0.1361, -0.0106, -0.0009]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0133, -0.0102, -0.0167],\n",
      "          [ 0.0605,  0.0396,  0.0381],\n",
      "          [ 0.0022, -0.0378,  0.0284]],\n",
      "\n",
      "         [[-0.0021, -0.0038,  0.0224],\n",
      "          [ 0.0428,  0.0491,  0.0343],\n",
      "          [ 0.0315,  0.0078,  0.0739]],\n",
      "\n",
      "         [[ 0.0245,  0.0044,  0.0138],\n",
      "          [ 0.0125, -0.0444, -0.0249],\n",
      "          [-0.0233, -0.0033, -0.0083]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0323,  0.0718,  0.0707],\n",
      "          [ 0.0875,  0.0262,  0.0189],\n",
      "          [ 0.0498,  0.0483,  0.1019]],\n",
      "\n",
      "         [[-0.0003,  0.0429,  0.0093],\n",
      "          [-0.0055,  0.0062, -0.0420],\n",
      "          [-0.1359, -0.0586, -0.0223]],\n",
      "\n",
      "         [[ 0.0458,  0.0274,  0.0121],\n",
      "          [ 0.0201,  0.0714,  0.0482],\n",
      "          [ 0.0574,  0.0456, -0.0101]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0270,  0.0871,  0.0691],\n",
      "          [ 0.0668,  0.0525,  0.0720],\n",
      "          [-0.0112,  0.0407,  0.0294]],\n",
      "\n",
      "         [[-0.0164,  0.0109, -0.0060],\n",
      "          [ 0.0782, -0.0270, -0.0033],\n",
      "          [ 0.0360,  0.0177,  0.0553]],\n",
      "\n",
      "         [[-0.0484, -0.0011,  0.0270],\n",
      "          [ 0.0333, -0.0043,  0.0306],\n",
      "          [ 0.0454, -0.0117, -0.0212]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0250,  0.0813,  0.0508],\n",
      "          [-0.0472,  0.0213,  0.0307],\n",
      "          [ 0.0116, -0.0202,  0.0589]],\n",
      "\n",
      "         [[ 0.0120,  0.0130, -0.0056],\n",
      "          [-0.0028, -0.0234,  0.0488],\n",
      "          [ 0.0257, -0.0366, -0.0253]],\n",
      "\n",
      "         [[ 0.0699,  0.0639,  0.0803],\n",
      "          [ 0.0938,  0.0896,  0.0338],\n",
      "          [-0.0369, -0.0531, -0.0128]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0017,  0.0260,  0.0288],\n",
      "          [-0.0411, -0.0134,  0.0313],\n",
      "          [-0.0594, -0.0658, -0.0302]],\n",
      "\n",
      "         [[ 0.0140,  0.0814, -0.0375],\n",
      "          [-0.0381, -0.1109, -0.0823],\n",
      "          [-0.0197, -0.0450, -0.0710]],\n",
      "\n",
      "         [[ 0.0071, -0.0512, -0.0125],\n",
      "          [-0.0467, -0.0908, -0.1123],\n",
      "          [-0.0172, -0.0578, -0.0195]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0156, -0.0290, -0.0896],\n",
      "          [-0.0079,  0.0366,  0.0295],\n",
      "          [ 0.0115,  0.0290,  0.0330]],\n",
      "\n",
      "         [[ 0.0795,  0.0345, -0.0546],\n",
      "          [ 0.0245,  0.0264, -0.0190],\n",
      "          [ 0.0493,  0.0884,  0.0653]],\n",
      "\n",
      "         [[-0.0396,  0.0067,  0.0473],\n",
      "          [ 0.0531,  0.0353,  0.0584],\n",
      "          [ 0.0683, -0.0240,  0.0134]]],\n",
      "\n",
      "\n",
      "        [[[-0.0389, -0.0505, -0.1451],\n",
      "          [-0.0106, -0.0241, -0.0646],\n",
      "          [ 0.0090, -0.0420, -0.0394]],\n",
      "\n",
      "         [[-0.0010, -0.0384, -0.0692],\n",
      "          [-0.0634, -0.0398, -0.0299],\n",
      "          [ 0.0315,  0.0770,  0.0654]],\n",
      "\n",
      "         [[-0.0294, -0.1129, -0.0988],\n",
      "          [-0.0534, -0.0890, -0.0206],\n",
      "          [-0.0801, -0.0543, -0.0153]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0332,  0.0775,  0.0633],\n",
      "          [ 0.0630,  0.0848,  0.0985],\n",
      "          [ 0.0119,  0.0558,  0.0993]],\n",
      "\n",
      "         [[ 0.0118, -0.0482,  0.0608],\n",
      "          [ 0.0057,  0.1500,  0.1067],\n",
      "          [ 0.0378,  0.0994,  0.0242]],\n",
      "\n",
      "         [[-0.0052, -0.0131, -0.0788],\n",
      "          [ 0.0106,  0.0451, -0.0884],\n",
      "          [ 0.0022,  0.0388, -0.0656]]],\n",
      "\n",
      "\n",
      "        [[[-0.0272, -0.0307, -0.0635],\n",
      "          [-0.0198, -0.0565, -0.0698],\n",
      "          [-0.0224, -0.0372, -0.0266]],\n",
      "\n",
      "         [[ 0.0276,  0.0683, -0.0414],\n",
      "          [-0.0496, -0.1049, -0.1142],\n",
      "          [-0.0502, -0.1142, -0.0138]],\n",
      "\n",
      "         [[-0.2166, -0.0743, -0.0454],\n",
      "          [-0.0591, -0.0040, -0.0036],\n",
      "          [-0.0110, -0.1166, -0.0004]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0109,  0.1607,  0.1655],\n",
      "          [-0.0537,  0.1359,  0.0930],\n",
      "          [ 0.0714,  0.0460, -0.0220]],\n",
      "\n",
      "         [[ 0.0322,  0.0057, -0.0776],\n",
      "          [ 0.0251,  0.0941, -0.0046],\n",
      "          [-0.0216,  0.0254, -0.0236]],\n",
      "\n",
      "         [[ 0.1092,  0.0620, -0.1711],\n",
      "          [ 0.0084, -0.1368, -0.1062],\n",
      "          [ 0.0905, -0.2329, -0.0532]]]], device='cuda:0')\n",
      "conv4.bias tensor([ 0.0506,  0.0073, -0.0036, -0.0182, -0.0104,  0.0228, -0.0735, -0.0545,\n",
      "        -0.0249,  0.0442, -0.0429,  0.0494, -0.0353, -0.0037,  0.0055, -0.1027,\n",
      "        -0.0172, -0.0259, -0.0770, -0.0387, -0.0257,  0.0286, -0.0233,  0.0370,\n",
      "         0.0490, -0.0434,  0.0379,  0.0443, -0.0178,  0.0413,  0.0636, -0.0066,\n",
      "        -0.0446, -0.0455, -0.0175, -0.0219, -0.0119,  0.0416,  0.0254,  0.0445,\n",
      "        -0.0375, -0.0516, -0.0667, -0.0282, -0.0387, -0.0655,  0.0227, -0.0671,\n",
      "        -0.0239,  0.0289, -0.0778, -0.0070,  0.0816, -0.0328,  0.0113, -0.0257,\n",
      "         0.0181, -0.0022, -0.0497,  0.0286,  0.0179, -0.0107,  0.0058,  0.0235,\n",
      "        -0.0231, -0.0142, -0.0045,  0.0525, -0.0815, -0.0030,  0.0147,  0.0104,\n",
      "        -0.0503, -0.0288, -0.0106,  0.0075, -0.0235,  0.0412, -0.0244,  0.0119,\n",
      "        -0.0116, -0.0074,  0.0314, -0.0194, -0.0453,  0.0285,  0.0413, -0.0763,\n",
      "        -0.0403,  0.0043, -0.0064, -0.0928, -0.0335, -0.0793, -0.0002, -0.0084,\n",
      "         0.0536,  0.0413, -0.0191, -0.0443,  0.0589, -0.0008,  0.0289, -0.0171,\n",
      "        -0.0480,  0.0173, -0.0014,  0.0847,  0.0011, -0.0265, -0.0264, -0.0374,\n",
      "         0.0167, -0.0044,  0.0135, -0.0065, -0.0045, -0.0259, -0.0320, -0.0057,\n",
      "        -0.0547, -0.0128,  0.0021, -0.0206,  0.0138, -0.0363, -0.0370, -0.0682],\n",
      "       device='cuda:0')\n",
      "linear.weight tensor([[ 6.5876e-03,  1.4104e-02,  2.3642e-02,  ..., -1.2169e-01,\n",
      "         -4.1353e-02, -1.0693e-02],\n",
      "        [ 7.8332e-04, -2.6056e-04,  2.2412e-02,  ..., -6.1573e-03,\n",
      "         -1.7840e-02, -2.0513e-02],\n",
      "        [-1.0386e-02, -5.4916e-03,  1.1474e-02,  ..., -7.6585e-02,\n",
      "         -2.3367e-02,  1.3832e-02],\n",
      "        ...,\n",
      "        [-1.8661e-03, -1.5096e-02, -3.9980e-03,  ...,  9.8946e-02,\n",
      "         -1.7018e-02, -2.1703e-02],\n",
      "        [-5.2784e-03,  1.1937e-02,  7.9528e-03,  ...,  2.4129e-02,\n",
      "          1.2945e-02,  1.0196e-02],\n",
      "        [ 6.1172e-04, -1.1294e-04, -4.5204e-03,  ...,  8.9026e-02,\n",
      "          3.1165e-02,  1.6876e-02]], device='cuda:0')\n",
      "linear.bias tensor([-0.0029,  0.0253, -0.0119,  0.0047,  0.0080,  0.0114, -0.0029,  0.0103,\n",
      "        -0.0126, -0.0114], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
